{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gold Price Prediction with News Integration\n",
    "\n",
    "This notebook predicts gold price direction (up/down) and price range using:\n",
    "- Historical gold price data from Kaggle\n",
    "- Google RSS news feeds for latest news sentiment\n",
    "- Real-time gold price API for current prices\n",
    "\n",
    "## Prediction Goals\n",
    "1. Predict whether gold price will go UP or DOWN\n",
    "2. Predict the price range/amount of change\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Configuration\n",
    "\n",
    "Set your Kaggle API token here (or use environment variables in Colab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "KAGGLE_API_TOKEN = \"KGAT_b352cb91c46b038224e3d90adb8d8c32\"\n",
    "ALPHA_VANTAGE_API_KEY = \"EF6488BOEZN0B69R\"\n",
    "\n",
    "# Set environment variable for Kaggle\n",
    "import os\n",
    "os.environ['KAGGLE_API_TOKEN'] = KAGGLE_API_TOKEN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Setup and Installation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install required packages\n",
    "!pip install kagglehub pandas numpy scikit-learn matplotlib seaborn feedparser requests beautifulsoup4 textblob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/sid321axn/gold-price-prediction-dataset?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371k/371k [00:00<00:00, 665kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n",
      "Path to dataset files: C:\\Users\\miste\\.cache\\kagglehub\\datasets\\sid321axn\\gold-price-prediction-dataset\\versions\\1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Download Kaggle dataset using kagglehub\n",
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"sid321axn/gold-price-prediction-dataset\")\n",
    "print(\"Path to dataset files:\", path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For RSS feeds and news\n",
    "import feedparser\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from textblob import TextBlob\n",
    "\n",
    "# For API calls\n",
    "import json\n",
    "import time\n",
    "\n",
    "# For machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, classification_report, mean_absolute_error, mean_squared_error\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import joblib\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Explore Kaggle Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset located at: C:\\Users\\miste\\.cache\\kagglehub\\datasets\\sid321axn\\gold-price-prediction-dataset\\versions\\1\n",
      "Files in dataset: ['FINAL_USO.csv']\n",
      "\n",
      "Loaded: FINAL_USO.csv\n",
      "Shape: (1718, 81)\n",
      "\n",
      "First few rows:\n",
      "         Date        Open        High         Low       Close   Adj Close  \\\n",
      "0  2011-12-15  154.740005  154.949997  151.710007  152.330002  152.330002   \n",
      "1  2011-12-16  154.309998  155.369995  153.899994  155.229996  155.229996   \n",
      "2  2011-12-19  155.479996  155.860001  154.360001  154.869995  154.869995   \n",
      "3  2011-12-20  156.820007  157.429993  156.580002  156.979996  156.979996   \n",
      "4  2011-12-21  156.979996  157.529999  156.130005  157.160004  157.160004   \n",
      "\n",
      "     Volume     SP_open     SP_high      SP_low  ...    GDX_Low  GDX_Close  \\\n",
      "0  21521900  123.029999  123.199997  121.989998  ...  51.570000  51.680000   \n",
      "1  18124300  122.230003  122.949997  121.300003  ...  52.040001  52.680000   \n",
      "2  12547200  122.059998  122.320000  120.029999  ...  51.029999  51.169998   \n",
      "3   9136300  122.180000  124.139999  120.370003  ...  52.369999  52.990002   \n",
      "4  11996100  123.930000  124.360001  122.750000  ...  52.419998  52.959999   \n",
      "\n",
      "   GDX_Adj Close  GDX_Volume   USO_Open   USO_High    USO_Low  USO_Close  \\\n",
      "0      48.973877    20605600  36.900002  36.939999  36.049999  36.130001   \n",
      "1      49.921513    16285400  36.180000  36.500000  35.730000  36.270000   \n",
      "2      48.490578    15120200  36.389999  36.450001  35.930000  36.200001   \n",
      "3      50.215282    11644900  37.299999  37.610001  37.220001  37.560001   \n",
      "4      50.186852     8724300  37.669998  38.240002  37.520000  38.110001   \n",
      "\n",
      "   USO_Adj Close  USO_Volume  \n",
      "0      36.130001    12616700  \n",
      "1      36.270000    12578800  \n",
      "2      36.200001     7418200  \n",
      "3      37.560001    10041600  \n",
      "4      38.110001    10728000  \n",
      "\n",
      "[5 rows x 81 columns]\n",
      "\n",
      "Column names: ['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'SP_open', 'SP_high', 'SP_low', 'SP_close', 'SP_Ajclose', 'SP_volume', 'DJ_open', 'DJ_high', 'DJ_low', 'DJ_close', 'DJ_Ajclose', 'DJ_volume', 'EG_open', 'EG_high', 'EG_low', 'EG_close', 'EG_Ajclose', 'EG_volume', 'EU_Price', 'EU_open', 'EU_high', 'EU_low', 'EU_Trend', 'OF_Price', 'OF_Open', 'OF_High', 'OF_Low', 'OF_Volume', 'OF_Trend', 'OS_Price', 'OS_Open', 'OS_High', 'OS_Low', 'OS_Trend', 'SF_Price', 'SF_Open', 'SF_High', 'SF_Low', 'SF_Volume', 'SF_Trend', 'USB_Price', 'USB_Open', 'USB_High', 'USB_Low', 'USB_Trend', 'PLT_Price', 'PLT_Open', 'PLT_High', 'PLT_Low', 'PLT_Trend', 'PLD_Price', 'PLD_Open', 'PLD_High', 'PLD_Low', 'PLD_Trend', 'RHO_PRICE', 'USDI_Price', 'USDI_Open', 'USDI_High', 'USDI_Low', 'USDI_Volume', 'USDI_Trend', 'GDX_Open', 'GDX_High', 'GDX_Low', 'GDX_Close', 'GDX_Adj Close', 'GDX_Volume', 'USO_Open', 'USO_High', 'USO_Low', 'USO_Close', 'USO_Adj Close', 'USO_Volume']\n",
      "\n",
      "Data types:\n",
      "Date              object\n",
      "Open             float64\n",
      "High             float64\n",
      "Low              float64\n",
      "Close            float64\n",
      "                  ...   \n",
      "USO_High         float64\n",
      "USO_Low          float64\n",
      "USO_Close        float64\n",
      "USO_Adj Close    float64\n",
      "USO_Volume         int64\n",
      "Length: 81, dtype: object\n",
      "\n",
      "Basic statistics:\n",
      "              Open         High          Low        Close    Adj Close  \\\n",
      "count  1718.000000  1718.000000  1718.000000  1718.000000  1718.000000   \n",
      "mean    127.323434   127.854237   126.777695   127.319482   127.319482   \n",
      "std      17.526993    17.631189    17.396513    17.536269    17.536269   \n",
      "min     100.919998   100.989998   100.230003   100.500000   100.500000   \n",
      "25%     116.220001   116.540001   115.739998   116.052502   116.052502   \n",
      "50%     121.915001   122.325001   121.369999   121.795002   121.795002   \n",
      "75%     128.427494   129.087498   127.840001   128.470001   128.470001   \n",
      "max     173.199997   174.070007   172.919998   173.610001   173.610001   \n",
      "\n",
      "             Volume      SP_open      SP_high       SP_low     SP_close  ...  \\\n",
      "count  1.718000e+03  1718.000000  1718.000000  1718.000000  1718.000000  ...   \n",
      "mean   8.446327e+06   204.490023   205.372637   203.487014   204.491222  ...   \n",
      "std    4.920731e+06    43.831928    43.974644    43.618940    43.776999  ...   \n",
      "min    1.501600e+06   122.059998   122.320000   120.029999   120.290001  ...   \n",
      "25%    5.412925e+06   170.392498   170.962506   169.577499   170.397500  ...   \n",
      "50%    7.483900e+06   205.464996   206.459999   204.430000   205.529999  ...   \n",
      "75%    1.020795e+07   237.292500   237.722500   236.147503   236.889996  ...   \n",
      "max    9.380420e+07   293.089996   293.940002   291.809998   293.579987  ...   \n",
      "\n",
      "           GDX_Low    GDX_Close  GDX_Adj Close    GDX_Volume     USO_Open  \\\n",
      "count  1718.000000  1718.000000    1718.000000  1.718000e+03  1718.000000   \n",
      "mean     26.384575    26.715012      25.924624  4.356515e+07    22.113417   \n",
      "std      10.490908    10.603110       9.886570  2.909151e+07    11.431056   \n",
      "min      12.400000    12.470000      12.269618  4.729000e+06     7.820000   \n",
      "25%      20.355000    20.585000      20.180950  2.259968e+07    11.420000   \n",
      "50%      22.870001    23.054999      22.677604  3.730465e+07    16.450000   \n",
      "75%      26.797500    27.317500      26.478154  5.697055e+07    34.419998   \n",
      "max      56.770000    57.470001      54.617039  2.321536e+08    41.599998   \n",
      "\n",
      "          USO_High      USO_Low    USO_Close  USO_Adj Close    USO_Volume  \n",
      "count  1718.000000  1718.000000  1718.000000    1718.000000  1.718000e+03  \n",
      "mean     22.307148    21.904657    22.109051      22.109051  1.922313e+07  \n",
      "std      11.478671    11.373997    11.432787      11.432787  1.575743e+07  \n",
      "min       8.030000     7.670000     7.960000       7.960000  1.035100e+06  \n",
      "25%      11.500000    11.300000    11.392500      11.392500  6.229500e+06  \n",
      "50%      16.635001    16.040000    16.345000      16.345000  1.613015e+07  \n",
      "75%      34.667499    34.110000    34.417499      34.417499  2.672375e+07  \n",
      "max      42.299999    41.299999    42.009998      42.009998  1.102657e+08  \n",
      "\n",
      "[8 rows x 80 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "# Adjust the path based on your downloaded dataset structure\n",
    "dataset_path = path\n",
    "print(f\"Dataset located at: {dataset_path}\")\n",
    "\n",
    "# List files in the dataset\n",
    "if os.path.exists(dataset_path):\n",
    "    files = os.listdir(dataset_path)\n",
    "    print(\"Files in dataset:\", files)\n",
    "    \n",
    "    # Load the main CSV file (adjust filename as needed)\n",
    "    csv_files = [f for f in files if f.endswith('.csv')]\n",
    "    if csv_files:\n",
    "        df_gold = pd.read_csv(os.path.join(dataset_path, csv_files[0]))\n",
    "        print(f\"\\nLoaded: {csv_files[0]}\")\n",
    "        print(f\"Shape: {df_gold.shape}\")\n",
    "        print(f\"\\nFirst few rows:\")\n",
    "        print(df_gold.head())\n",
    "        print(f\"\\nColumn names: {df_gold.columns.tolist()}\")\n",
    "        print(f\"\\nData types:\\n{df_gold.dtypes}\")\n",
    "        print(f\"\\nBasic statistics:\\n{df_gold.describe()}\")\n",
    "    else:\n",
    "        print(\"No CSV files found in dataset\")\n",
    "else:\n",
    "    print(\"Dataset path not found. Please check the path.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Google RSS News Integration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not load ML news classifier, only basic filtering will be used. [Errno 2] No such file or directory: 'ml_models/gold_news_classifier.pkl'\n",
      "ðŸš€ Starting intelligent news collection for gold price prediction...\n",
      "\n",
      "ðŸ” Fetching comprehensive news coverage using 17 query variations...\n",
      "   Including: Gold markets, Economics, Geopolitics, Politics, Financial markets\n",
      "======================================================================\n",
      "[1/17] Query: gold price OR gold market OR gold trading OR gold futures...\n",
      "    âœ“ Retrieved 50 articles\n",
      "[2/17] Query: precious metals OR gold OR silver OR commodities...\n",
      "    âœ“ Retrieved 50 articles\n",
      "[3/17] Query: inflation OR deflation OR CPI OR consumer price index...\n",
      "    âœ“ Retrieved 50 articles\n",
      "[4/17] Query: interest rate OR federal reserve OR central bank OR monetary poli...\n",
      "    âœ“ Retrieved 50 articles\n",
      "[5/17] Query: USD OR dollar OR currency exchange OR forex...\n",
      "    âœ“ Retrieved 50 articles\n",
      "[6/17] Query: geopolitical OR war OR conflict OR sanctions OR military...\n",
      "    âœ“ Retrieved 50 articles\n",
      "[7/17] Query: trade war OR tariffs OR trade policy OR international trade...\n",
      "    âœ“ Retrieved 50 articles\n",
      "[8/17] Query: political instability OR election OR government policy OR politic...\n",
      "    âœ“ Retrieved 50 articles\n",
      "[9/17] Query: international relations OR diplomacy OR foreign policy...\n",
      "    âœ“ Retrieved 50 articles\n",
      "[10/17] Query: political news OR politics OR government OR administration...\n",
      "    âœ“ Retrieved 50 articles\n",
      "[11/17] Query: recession OR economic downturn OR market crash OR economic crisis...\n",
      "    âœ“ Retrieved 50 articles\n",
      "[12/17] Query: economic growth OR GDP OR unemployment OR employment...\n",
      "    âœ“ Retrieved 50 articles\n",
      "[13/17] Query: stock market OR bonds OR treasury OR debt OR financial markets...\n",
      "    âœ“ Retrieved 50 articles\n",
      "[14/17] Query: oil price OR energy OR commodities market OR raw materials...\n",
      "    âœ“ Retrieved 50 articles\n",
      "[15/17] Query: mining OR production OR supply chain OR commodity prices...\n",
      "    âœ“ Retrieved 50 articles\n",
      "[16/17] Query: safe haven OR hedge OR investment OR asset allocation...\n",
      "    âœ“ Retrieved 50 articles\n",
      "[17/17] Query: market volatility OR financial crisis OR banking crisis...\n",
      "    âœ“ Retrieved 50 articles\n",
      "\n",
      "ðŸ“Š Total articles retrieved: 850\n",
      "ðŸ”§ Removing duplicates...\n",
      "   After deduplication: 839 unique articles\n",
      "\n",
      "ðŸ§  Applying intelligent filtering...\n",
      "âœ“ 839 highly relevant articles selected\n",
      "======================================================================\n",
      "\n",
      "ðŸ“° Sample of most impactful news (sorted by relevance):\n",
      "======================================================================\n",
      "                                                title  \\\n",
      "0   Collapse of commodity and oil prices is everyb...   \n",
      "1   The Impact of the Trade War on Canada - Econofact   \n",
      "2   Finding a Firmer Footing: The Case for Commerc...   \n",
      "3   Federal Reserve cuts interest rates 0.25%, whi...   \n",
      "4   Federal Reserve cuts interest rates by 0.25 pe...   \n",
      "5   Federal Reserve meets today for an interest ra...   \n",
      "6   US Federal Reserve cuts interest rates as labo...   \n",
      "7   Trump 'losing' trade war with China going in t...   \n",
      "8   Why a US-China trade deal matters to the globa...   \n",
      "9                A crash is coming - Engelsberg Ideas   \n",
      "10  The rise and fall of globalisation: why the wo...   \n",
      "11  Understanding Bear Markets: History, Causes, a...   \n",
      "12       2026 Oil and Gas Industry Outlook - Deloitte   \n",
      "13  Professor: Supply Chain Management Can Strengt...   \n",
      "14  Commodity markets in 2022: A year in 8 infogra...   \n",
      "\n",
      "                        published  ml_pred  \\\n",
      "0   Wed, 30 Mar 2016 07:00:00 GMT      1.0   \n",
      "1   Wed, 30 Jul 2025 07:00:00 GMT      1.0   \n",
      "2   Wed, 30 Jul 2025 07:00:00 GMT      1.0   \n",
      "3   Wed, 29 Oct 2025 07:00:00 GMT      1.0   \n",
      "4   Wed, 29 Oct 2025 07:00:00 GMT      1.0   \n",
      "5   Wed, 29 Oct 2025 07:00:00 GMT      1.0   \n",
      "6   Wed, 29 Oct 2025 07:00:00 GMT      1.0   \n",
      "7   Wed, 29 Oct 2025 07:00:00 GMT      1.0   \n",
      "8   Wed, 29 Oct 2025 07:00:00 GMT      1.0   \n",
      "9   Wed, 29 Oct 2025 07:00:00 GMT      1.0   \n",
      "10  Wed, 29 Oct 2025 07:00:00 GMT      1.0   \n",
      "11  Wed, 29 Oct 2025 07:00:00 GMT      1.0   \n",
      "12  Wed, 29 Oct 2025 07:00:00 GMT      1.0   \n",
      "13  Wed, 29 Oct 2025 07:00:00 GMT      1.0   \n",
      "14  Wed, 28 Dec 2022 08:00:00 GMT      1.0   \n",
      "\n",
      "                                                 link  \n",
      "0   https://news.google.com/rss/articles/CBMimAFBV...  \n",
      "1   https://news.google.com/rss/articles/CBMia0FVX...  \n",
      "2   https://news.google.com/rss/articles/CBMirgFBV...  \n",
      "3   https://news.google.com/rss/articles/CBMipAFBV...  \n",
      "4   https://news.google.com/rss/articles/CBMikAFBV...  \n",
      "5   https://news.google.com/rss/articles/CBMiowFBV...  \n",
      "6   https://news.google.com/rss/articles/CBMirAFBV...  \n",
      "7   https://news.google.com/rss/articles/CBMijAFBV...  \n",
      "8   https://news.google.com/rss/articles/CBMiogFBV...  \n",
      "9   https://news.google.com/rss/articles/CBMiY0FVX...  \n",
      "10  https://news.google.com/rss/articles/CBMi7gFBV...  \n",
      "11  https://news.google.com/rss/articles/CBMib0FVX...  \n",
      "12  https://news.google.com/rss/articles/CBMimgFBV...  \n",
      "13  https://news.google.com/rss/articles/CBMivgFBV...  \n",
      "14  https://news.google.com/rss/articles/CBMiuwFBV...  \n",
      "\n",
      "âœ“ Total impactful news articles: 839\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Load pretrained ML model and vectorizer (must be trained and exported separately)\n",
    "ML_MODEL_PATH = \"ml_models/gold_news_classifier.pkl\"\n",
    "VECTORIZER_PATH = \"ml_models/vectorizer.pkl\"\n",
    "try:\n",
    "    gold_news_classifier = joblib.load(ML_MODEL_PATH)\n",
    "    news_vectorizer = joblib.load(VECTORIZER_PATH)\n",
    "except Exception as e:\n",
    "    print(\"Warning: Could not load ML news classifier, only basic filtering will be used.\", e)\n",
    "    gold_news_classifier = None\n",
    "    news_vectorizer = None\n",
    "\n",
    "def fetch_global_news(query, max_results=100, language=\"en\"):\n",
    "    \"\"\"\n",
    "    Fetch worldwide news articles from Google News RSS (global coverage, no region lock).\n",
    "    Automatically handles query encoding and retries on errors.\n",
    "    \"\"\"\n",
    "    from urllib.parse import quote_plus\n",
    "    encoded_query = quote_plus(query)\n",
    "    \n",
    "    # Use global RSS feed without region restrictions\n",
    "    rss_url = f\"https://news.google.com/rss/search?q={encoded_query}&hl={language}&gl=US&ceid=US:{language.upper()}\"\n",
    "    try:\n",
    "        feed = feedparser.parse(rss_url)\n",
    "        news_items = []\n",
    "        for entry in feed.entries[:max_results]:\n",
    "            title = entry.get('title', '').replace('<b>', '').replace('</b>', '')\n",
    "            summary = entry.get('summary', '').replace('<b>', '').replace('</b>', '')\n",
    "            published = entry.get('published', '')\n",
    "            link = entry.get('link', '')\n",
    "            \n",
    "            news_items.append({\n",
    "                'title': title,\n",
    "                'summary': summary,\n",
    "                'published': published,\n",
    "                'link': link,\n",
    "                'full_text': f\"{title} {summary}\"\n",
    "            })\n",
    "        return pd.DataFrame(news_items)\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching news: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def ml_filter_impactful_news(news_df, threshold=0.6):\n",
    "    \"\"\"\n",
    "    Use loaded ML model to filter which news are most likely to influence gold prices.\n",
    "    Assumes a binary or multi-class classifier, with probability output.\n",
    "    Returns dataframe with predicted probabilities and filter column.\n",
    "    \"\"\"\n",
    "    if gold_news_classifier is None or news_vectorizer is None or news_df.empty:\n",
    "        # Fallback: keep all news\n",
    "        news_df['ml_pred'] = 1.0  # mark all as relevant\n",
    "        news_df['ml_relevant'] = True\n",
    "        return news_df\n",
    "\n",
    "    # Use both title and summary for classification input\n",
    "    texts = (news_df['title'].fillna('') + ' ' + news_df['summary'].fillna('')).tolist()\n",
    "    X = news_vectorizer.transform(texts)\n",
    "    if hasattr(gold_news_classifier, \"predict_proba\"):\n",
    "        proba = gold_news_classifier.predict_proba(X)[:, 1]  # 2nd col = positive (relevant to gold pricing)\n",
    "    else:\n",
    "        # For classifier that doesn't support proba\n",
    "        proba = gold_news_classifier.decision_function(X)\n",
    "        proba = (proba - proba.min()) / (proba.max() - proba.min() + 1e-8)  # Scale to [0, 1]\n",
    "    news_df['ml_pred'] = proba\n",
    "    news_df['ml_relevant'] = news_df['ml_pred'] > threshold\n",
    "    return news_df\n",
    "\n",
    "def get_recent_impactful_gold_news(max_results=50):\n",
    "    \"\"\"\n",
    "    Fetch a broad set of global economic & gold/finance news, then filter using ML model.\n",
    "    Only return news predicted by the model to be recent and impactful for gold pricing.\n",
    "    \"\"\"\n",
    "    # Query includes gold and broader relevant terms for global coverage\n",
    "    global_query = (\n",
    "        \"gold OR gold price OR inflation OR dollar OR \"\n",
    "        \"interest rate OR central bank OR economy OR \"\n",
    "        \"currency OR commodities OR market crash OR recession\"\n",
    "    )\n",
    "    print(\"Fetching global news (broad)...\")\n",
    "    news_df = fetch_global_news(query=global_query, max_results=max_results * 3)\n",
    "    if news_df.empty:\n",
    "        print(\"No news items retrieved.\")\n",
    "        return news_df\n",
    "\n",
    "    # ML FILTER: Intelligent filter for news likely to affect gold prices\n",
    "    news_df_filtered = ml_filter_impactful_news(news_df)\n",
    "    impactful_df = news_df_filtered[news_df_filtered['ml_relevant']].sort_values(\"published\", ascending=False)\n",
    "    impactful_df = impactful_df.reset_index(drop=True).head(max_results)\n",
    "    print(f\"Selected {len(impactful_df)} recent, impactful news potentially influencing gold prices.\")\n",
    "    return impactful_df\n",
    "\n",
    "def generate_query_variations():\n",
    "    \"\"\"\n",
    "    Generate multiple query variations to capture ALL relevant news.\n",
    "    Automatically refines queries to cover different aspects affecting gold including politics.\n",
    "    \"\"\"\n",
    "    base_queries = [\n",
    "        # Direct gold-related\n",
    "        \"gold price OR gold market OR gold trading OR gold futures\",\n",
    "        \"precious metals OR gold OR silver OR commodities\",\n",
    "        \n",
    "        # Economic indicators\n",
    "        \"inflation OR deflation OR CPI OR consumer price index\",\n",
    "        \"interest rate OR federal reserve OR central bank OR monetary policy\",\n",
    "        \"USD OR dollar OR currency exchange OR forex\",\n",
    "        \n",
    "        # Geopolitical & Political (Critical for gold)\n",
    "        \"geopolitical OR war OR conflict OR sanctions OR military\",\n",
    "        \"trade war OR tariffs OR trade policy OR international trade\",\n",
    "        \"political instability OR election OR government policy OR political crisis\",\n",
    "        \"international relations OR diplomacy OR foreign policy\",\n",
    "        \"political news OR politics OR government OR administration\",\n",
    "        \n",
    "        # Economic conditions\n",
    "        \"recession OR economic downturn OR market crash OR economic crisis\",\n",
    "        \"economic growth OR GDP OR unemployment OR employment\",\n",
    "        \"stock market OR bonds OR treasury OR debt OR financial markets\",\n",
    "        \n",
    "        # Commodities & Energy\n",
    "        \"oil price OR energy OR commodities market OR raw materials\",\n",
    "        \"mining OR production OR supply chain OR commodity prices\",\n",
    "        \n",
    "        # Financial markets\n",
    "        \"safe haven OR hedge OR investment OR asset allocation\",\n",
    "        \"market volatility OR financial crisis OR banking crisis\",\n",
    "    ]\n",
    "    \n",
    "    return base_queries\n",
    "\n",
    "def get_all_relevant_gold_news(max_results_per_query=50, min_relevance_score=0.5):\n",
    "    \"\"\"\n",
    "    Intelligently fetches ALL news that could affect gold pricing including politics.\n",
    "    Uses multiple query variations and automatic filtering.\n",
    "    Automatically refines queries to find comprehensive coverage.\n",
    "    Returns complete news dataset sorted by relevance.\n",
    "    \"\"\"\n",
    "    all_news = []\n",
    "    queries = generate_query_variations()\n",
    "    \n",
    "    print(f\"ðŸ” Fetching comprehensive news coverage using {len(queries)} query variations...\")\n",
    "    print(\"   Including: Gold markets, Economics, Geopolitics, Politics, Financial markets\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    for i, query in enumerate(queries, 1):\n",
    "        print(f\"[{i}/{len(queries)}] Query: {query[:65]}...\")\n",
    "        try:\n",
    "            news_batch = fetch_global_news(query, max_results=max_results_per_query)\n",
    "            if not news_batch.empty:\n",
    "                all_news.append(news_batch)\n",
    "                print(f\"    âœ“ Retrieved {len(news_batch)} articles\")\n",
    "            else:\n",
    "                print(f\"    âš  No results\")\n",
    "        except Exception as e:\n",
    "            print(f\"    âœ— Error: {e}\")\n",
    "        \n",
    "        # Small delay to avoid rate limiting\n",
    "        time.sleep(0.3)\n",
    "    \n",
    "    if not all_news:\n",
    "        print(\"\\nâŒ No news retrieved from any queries\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Combine all news\n",
    "    combined_news = pd.concat(all_news, ignore_index=True)\n",
    "    \n",
    "    # Remove duplicates based on title\n",
    "    print(f\"\\nðŸ“Š Total articles retrieved: {len(combined_news)}\")\n",
    "    print(\"ðŸ”§ Removing duplicates...\")\n",
    "    \n",
    "    combined_news = combined_news.drop_duplicates(subset=['title'], keep='first')\n",
    "    print(f\"   After deduplication: {len(combined_news)} unique articles\")\n",
    "    \n",
    "    # Apply intelligent filtering\n",
    "    print(\"\\nðŸ§  Applying intelligent filtering...\")\n",
    "    filtered_news = ml_filter_impactful_news(combined_news, threshold=min_relevance_score)\n",
    "    \n",
    "    # Filter to most relevant\n",
    "    relevant_news = filtered_news[filtered_news['ml_relevant']].copy()\n",
    "    \n",
    "    # Sort by relevance score and recency\n",
    "    relevant_news = relevant_news.sort_values(\n",
    "        ['ml_pred', 'published'], \n",
    "        ascending=[False, False]\n",
    "    ).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"âœ“ {len(relevant_news)} highly relevant articles selected\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    return relevant_news\n",
    "\n",
    "# Automatically fetch and filter all relevant news\n",
    "print(\"ðŸš€ Starting intelligent news collection for gold price prediction...\\n\")\n",
    "impactful_news_df = get_all_relevant_gold_news(max_results_per_query=50, min_relevance_score=0.5)\n",
    "\n",
    "if not impactful_news_df.empty:\n",
    "    print(\"\\nðŸ“° Sample of most impactful news (sorted by relevance):\")\n",
    "    print(\"=\" * 70)\n",
    "    display_cols = ['title', 'published', 'ml_pred', 'link']\n",
    "    print(impactful_news_df[display_cols].head(15))\n",
    "    print(f\"\\nâœ“ Total impactful news articles: {len(impactful_news_df)}\")\n",
    "else:\n",
    "    print(\"âš ï¸  No impactful news found. Try lowering min_relevance_score or checking network connection.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Free Gold Price API Integration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching current gold price from Alpha Vantage...\n",
      "API Error: Invalid API call. Please retry or visit the documentation (https://www.alphavantage.co/documentation/) for CURRENCY_EXCHANGE_RATE.\n",
      "\n",
      "Warning: Could not fetch current gold price\n",
      "Using placeholder value for model training\n",
      "\n",
      "Gold Price Data: {'current_price': 2000.0, 'source': 'placeholder', 'timestamp': '2025-11-27T11:24:13.197773'}\n"
     ]
    }
   ],
   "source": [
    "def get_gold_price_api(api_key):\n",
    "    \"\"\"\n",
    "    Fetch current gold price using Alpha Vantage API\n",
    "    \"\"\"\n",
    "    if not api_key:\n",
    "        print(\"Error: Alpha Vantage API key is required\")\n",
    "        return {\n",
    "            'current_price': None,\n",
    "            'source': 'error',\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "    \n",
    "    try:\n",
    "        url = f\"https://www.alphavantage.co/query?function=CURRENCY_EXCHANGE_RATE&from_currency=XAU&to_currency=USD&apikey={api_key}\"\n",
    "        response = requests.get(url, timeout=10)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            \n",
    "            # Check for API error messages\n",
    "            if 'Error Message' in data:\n",
    "                print(f\"API Error: {data['Error Message']}\")\n",
    "                return {\n",
    "                    'current_price': None,\n",
    "                    'source': 'api_error',\n",
    "                    'timestamp': datetime.now().isoformat()\n",
    "                }\n",
    "            \n",
    "            if 'Note' in data:\n",
    "                print(f\"API Note: {data['Note']}\")\n",
    "                return {\n",
    "                    'current_price': None,\n",
    "                    'source': 'rate_limit',\n",
    "                    'timestamp': datetime.now().isoformat()\n",
    "                }\n",
    "            \n",
    "            # Extract exchange rate\n",
    "            rate_info = data.get('Realtime Currency Exchange Rate', {})\n",
    "            if rate_info:\n",
    "                current_price = float(rate_info.get('5. Exchange Rate', 0))\n",
    "                if current_price > 0:\n",
    "                    return {\n",
    "                        'current_price': current_price,\n",
    "                        'source': 'alpha-vantage',\n",
    "                        'timestamp': datetime.now().isoformat(),\n",
    "                        'last_updated': rate_info.get('6. Last Refreshed', ''),\n",
    "                        'time_zone': rate_info.get('7. Time Zone', '')\n",
    "                    }\n",
    "        \n",
    "        print(f\"Error: Unexpected API response (Status: {response.status_code})\")\n",
    "        return {\n",
    "            'current_price': None,\n",
    "            'source': 'api_error',\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching gold price: {e}\")\n",
    "        return {\n",
    "            'current_price': None,\n",
    "            'source': 'error',\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "\n",
    "# Fetch current gold price using Alpha Vantage (Enhanced method)\n",
    "print(\"Fetching current gold price from Alpha Vantage...\")\n",
    "print(\"Using GLD ETF (SPDR Gold Trust) - Most reliable method\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "current_gold_data = get_gold_price_api(ALPHA_VANTAGE_API_KEY)\n",
    "\n",
    "if current_gold_data.get('current_price'):\n",
    "    print(f\"\\nâœ“ Gold Price Retrieved Successfully!\")\n",
    "    print(f\"  Current Gold Price: ${current_gold_data['current_price']:.2f}/oz\")\n",
    "    print(f\"  GLD ETF Price: ${current_gold_data.get('gld_price', 'N/A'):.2f}\")\n",
    "    print(f\"  Method: {current_gold_data.get('method', 'N/A')}\")\n",
    "    print(f\"  Source: {current_gold_data['source']}\")\n",
    "    if 'last_refreshed' in current_gold_data:\n",
    "        print(f\"  Last Updated: {current_gold_data['last_refreshed']}\")\n",
    "    if 'time_zone' in current_gold_data:\n",
    "        print(f\"  Time Zone: {current_gold_data['time_zone']}\")\n",
    "    print(f\"  Conversion: GLD Ã— {current_gold_data.get('conversion_ratio', 10)} = Gold price/oz\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸  Warning: Could not fetch current gold price from Alpha Vantage\")\n",
    "    print(\"   All API methods failed. Using placeholder value for model training.\")\n",
    "    current_gold_data['current_price'] = 2000.0\n",
    "    current_gold_data['source'] = 'placeholder'\n",
    "    if 'error' in current_gold_data:\n",
    "        print(f\"   Error: {current_gold_data['error']}\")\n",
    "\n",
    "print(f\"\\n{'=' * 70}\")\n",
    "print(\"Gold Price Data Summary:\")\n",
    "print(f\"{'=' * 70}\")\n",
    "for key, value in current_gold_data.items():\n",
    "    if key != 'error':  # Skip error details in summary\n",
    "        print(f\"  {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_gold_data(df):\n",
    "    \"\"\"\n",
    "    Preprocess the gold price dataset\n",
    "    \"\"\"\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    # Convert date column to datetime (adjust column name as needed)\n",
    "    date_col = None\n",
    "    for col in df_processed.columns:\n",
    "        if 'date' in col.lower() or 'time' in col.lower():\n",
    "            date_col = col\n",
    "            break\n",
    "    \n",
    "    if date_col:\n",
    "        df_processed[date_col] = pd.to_datetime(df_processed[date_col], errors='coerce')\n",
    "        df_processed = df_processed.sort_values(date_col).reset_index(drop=True)\n",
    "    \n",
    "    # Identify price column (usually contains 'price', 'close', or 'value')\n",
    "    price_col = None\n",
    "    for col in df_processed.columns:\n",
    "        if 'price' in col.lower() or 'close' in col.lower() or 'value' in col.lower():\n",
    "            price_col = col\n",
    "            break\n",
    "    \n",
    "    # Create features\n",
    "    if price_col and df_processed[price_col].dtype in ['float64', 'int64']:\n",
    "        # Price change\n",
    "        df_processed['price_change'] = df_processed[price_col].diff()\n",
    "        df_processed['price_change_pct'] = df_processed[price_col].pct_change() * 100\n",
    "        \n",
    "        # Moving averages\n",
    "        df_processed['ma_7'] = df_processed[price_col].rolling(window=7).mean()\n",
    "        df_processed['ma_30'] = df_processed[price_col].rolling(window=30).mean()\n",
    "        \n",
    "        # Price volatility\n",
    "        df_processed['volatility'] = df_processed[price_col].rolling(window=7).std()\n",
    "        \n",
    "        # Price direction (target for classification)\n",
    "        df_processed['direction'] = (df_processed[price_col].shift(-1) > df_processed[price_col]).astype(int)\n",
    "        # Handle NaN in direction (last row will be NaN)\n",
    "        df_processed['direction'] = df_processed['direction'].fillna(0).astype(int)\n",
    "        \n",
    "        # Price range for next period (target for regression)\n",
    "        df_processed['next_price'] = df_processed[price_col].shift(-1)\n",
    "        # Create a temporary dataframe for min/max calculation\n",
    "        temp_df = pd.DataFrame({\n",
    "            'current': df_processed[price_col],\n",
    "            'next': df_processed['next_price']\n",
    "        })\n",
    "        df_processed['price_range_low'] = temp_df[['current', 'next']].min(axis=1)\n",
    "        df_processed['price_range_high'] = temp_df[['current', 'next']].max(axis=1)\n",
    "        df_processed['price_range'] = df_processed['price_range_high'] - df_processed['price_range_low']\n",
    "    \n",
    "    # Handle missing values - use forward and backward fill (modern pandas syntax)\n",
    "    df_processed = df_processed.bfill().ffill()\n",
    "    # Drop any remaining NaN rows\n",
    "    df_processed = df_processed.dropna()\n",
    "    \n",
    "    return df_processed, price_col, date_col\n",
    "\n",
    "# Preprocess the dataset\n",
    "if 'df_gold' in locals() and not df_gold.empty:\n",
    "    df_processed, price_col, date_col = preprocess_gold_data(df_gold)\n",
    "    print(f\"Processed dataset shape: {df_processed.shape}\")\n",
    "    print(f\"Price column: {price_col}\")\n",
    "    print(f\"Date column: {date_col}\")\n",
    "    print(f\"\\nProcessed data head:\")\n",
    "    print(df_processed.head())\n",
    "else:\n",
    "    print(\"Please load the dataset first in section 3\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Engineering with News and API Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_matrix(df_processed, news_sentiment=None, current_api_price=None):\n",
    "    \"\"\"\n",
    "    Create feature matrix combining historical data, news sentiment, and API price\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    \n",
    "    # Historical price features\n",
    "    if price_col and price_col in df_processed.columns:\n",
    "        feature_cols = [\n",
    "            price_col,\n",
    "            'price_change', 'price_change_pct',\n",
    "            'ma_7', 'ma_30', 'volatility'\n",
    "        ]\n",
    "        \n",
    "        # Add available features\n",
    "        available_features = [col for col in feature_cols if col in df_processed.columns]\n",
    "        X = df_processed[available_features].values\n",
    "        \n",
    "        # Add news sentiment features (if available)\n",
    "        if news_sentiment:\n",
    "            sentiment_features = [\n",
    "                news_sentiment.get('avg_sentiment', 0.0),\n",
    "                news_sentiment.get('avg_price_indicator', 0.0),\n",
    "                news_sentiment.get('avg_combined_sentiment', 0.0),\n",
    "                news_sentiment.get('positive_count', 0),\n",
    "                news_sentiment.get('negative_count', 0),\n",
    "                news_sentiment.get('rise_indicator_count', 0),\n",
    "                news_sentiment.get('fall_indicator_count', 0),\n",
    "                news_sentiment.get('news_count', 0)\n",
    "            ]\n",
    "            # Repeat sentiment for each row (or match by date if dates available)\n",
    "            sentiment_array = np.tile(sentiment_features, (len(X), 1))\n",
    "            X = np.hstack([X, sentiment_array])\n",
    "        \n",
    "        # Add current API price features (if available)\n",
    "        if current_api_price and 'current_price' in current_api_price:\n",
    "            api_price = current_api_price['current_price']\n",
    "            # Compare with last historical price\n",
    "            last_price = df_processed[price_col].iloc[-1] if len(df_processed) > 0 else api_price\n",
    "            price_diff = api_price - last_price\n",
    "            price_diff_pct = (price_diff / last_price) * 100\n",
    "            \n",
    "            api_features = np.array([[api_price, price_diff, price_diff_pct]])\n",
    "            api_features_tiled = np.tile(api_features, (len(X), 1))\n",
    "            X = np.hstack([X, api_features_tiled])\n",
    "        \n",
    "        return X, available_features\n",
    "    \n",
    "    return None, []\n",
    "\n",
    "# Create feature matrix\n",
    "if 'df_processed' in locals() and not df_processed.empty:\n",
    "    X, feature_names = create_feature_matrix(\n",
    "        df_processed,\n",
    "        news_sentiment=sentiment_stats if 'sentiment_stats' in locals() else None,\n",
    "        current_api_price=current_gold_data if 'current_gold_data' in locals() else None\n",
    "    )\n",
    "    \n",
    "    if X is not None:\n",
    "        print(f\"Feature matrix shape: {X.shape}\")\n",
    "        print(f\"Feature names: {feature_names}\")\n",
    "        print(f\"\\nFeature matrix sample:\")\n",
    "        print(X[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Training - Direction Prediction (Up/Down)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_direction_model(X, y_direction):\n",
    "    \"\"\"\n",
    "    Train a model to predict price direction (up/down)\n",
    "    \"\"\"\n",
    "    # Remove rows where target is NaN\n",
    "    valid_mask = ~np.isnan(y_direction)\n",
    "    X_clean = X[valid_mask]\n",
    "    y_clean = y_direction[valid_mask].astype(int)\n",
    "    \n",
    "    if len(X_clean) == 0:\n",
    "        print(\"No valid data for training\")\n",
    "        return None, None, None\n",
    "    \n",
    "    # Split data\n",
    "    # Check if we can stratify (need at least 2 samples per class)\n",
    "    unique_classes = np.unique(y_clean)\n",
    "    can_stratify = len(unique_classes) > 1 and all((y_clean == cls).sum() >= 2 for cls in unique_classes)\n",
    "    \n",
    "    if can_stratify:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_clean, y_clean, test_size=0.2, random_state=42, stratify=y_clean\n",
    "        )\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_clean, y_clean, test_size=0.2, random_state=42\n",
    "        )\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Train Random Forest Classifier\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Direction Prediction Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['Down', 'Up']))\n",
    "    \n",
    "    # Feature importance\n",
    "    num_features = len(model.feature_importances_)\n",
    "    feature_names_list = feature_names if 'feature_names' in globals() and len(feature_names) >= num_features else [f'feature_{i}' for i in range(num_features)]\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': feature_names_list[:num_features],\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(f\"\\nTop Features:\")\n",
    "    print(feature_importance.head(10))\n",
    "    \n",
    "    return model, scaler, feature_importance\n",
    "\n",
    "# Train direction model\n",
    "if 'X' in locals() and X is not None and 'df_processed' in locals():\n",
    "    if 'direction' in df_processed.columns:\n",
    "        y_direction = df_processed['direction'].values\n",
    "        \n",
    "        direction_model, direction_scaler, feature_importance = train_direction_model(X, y_direction)\n",
    "        \n",
    "        if direction_model is not None:\n",
    "            print(\"\\nDirection model trained successfully!\")\n",
    "    else:\n",
    "        print(\"Direction column not found. Creating it...\")\n",
    "        # Create direction column if it doesn't exist\n",
    "        if price_col in df_processed.columns:\n",
    "            df_processed['direction'] = (df_processed[price_col].shift(-1) > df_processed[price_col]).astype(int)\n",
    "            y_direction = df_processed['direction'].values\n",
    "            direction_model, direction_scaler, feature_importance = train_direction_model(X, y_direction)\n",
    "else:\n",
    "    print(\"Please complete data preprocessing first\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Training - Price Range Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_range_model(X, y_price):\n",
    "    \"\"\"\n",
    "    Train a model to predict price range (how much the price will change)\n",
    "    \"\"\"\n",
    "    # Remove rows where target is NaN\n",
    "    valid_mask = ~np.isnan(y_price)\n",
    "    X_clean = X[valid_mask]\n",
    "    y_clean = y_price[valid_mask]\n",
    "    \n",
    "    if len(X_clean) == 0:\n",
    "        print(\"No valid data for training\")\n",
    "        return None, None, None\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_clean, y_clean, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Train Random Forest Regressor for price prediction\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    print(f\"Price Range Prediction:\")\n",
    "    print(f\"Mean Absolute Error: ${mae:.2f}\")\n",
    "    print(f\"Root Mean Squared Error: ${rmse:.2f}\")\n",
    "    print(f\"Mean Actual Price: ${y_test.mean():.2f}\")\n",
    "    print(f\"Mean Predicted Price: ${y_pred.mean():.2f}\")\n",
    "    \n",
    "    return model, scaler, {'mae': mae, 'rmse': rmse}\n",
    "\n",
    "# Train range model\n",
    "if 'X' in locals() and X is not None and 'df_processed' in locals():\n",
    "    if 'next_price' in df_processed.columns:\n",
    "        y_price = df_processed['next_price'].values\n",
    "        \n",
    "        range_model, range_scaler, range_metrics = train_range_model(X, y_price)\n",
    "        \n",
    "        if range_model is not None:\n",
    "            print(\"\\nPrice range model trained successfully!\")\n",
    "    else:\n",
    "        print(\"Next price column not found. Please check data preprocessing.\")\n",
    "else:\n",
    "    print(\"Please complete data preprocessing first\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Make Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_gold_price(direction_model, direction_scaler, range_model, range_scaler, \n",
    "                       latest_features, current_price):\n",
    "    \"\"\"\n",
    "    Make predictions for gold price direction and range\n",
    "    \"\"\"\n",
    "    predictions = {}\n",
    "    \n",
    "    # Predict direction\n",
    "    if direction_model is not None and direction_scaler is not None:\n",
    "        # Use the latest features for prediction\n",
    "        latest_features_scaled = direction_scaler.transform([latest_features])\n",
    "        direction_proba = direction_model.predict_proba(latest_features_scaled)[0]\n",
    "        direction_pred = direction_model.predict(latest_features_scaled)[0]\n",
    "        \n",
    "        predictions['direction'] = 'UP' if direction_pred == 1 else 'DOWN'\n",
    "        predictions['direction_confidence'] = max(direction_proba) * 100\n",
    "        predictions['up_probability'] = direction_proba[1] * 100\n",
    "        predictions['down_probability'] = direction_proba[0] * 100\n",
    "    \n",
    "    # Predict price range\n",
    "    if range_model is not None and range_scaler is not None:\n",
    "        latest_features_scaled = range_scaler.transform([latest_features])\n",
    "        predicted_price = range_model.predict(latest_features_scaled)[0]\n",
    "        \n",
    "        # Calculate range\n",
    "        price_change = predicted_price - current_price\n",
    "        price_change_pct = (price_change / current_price) * 100\n",
    "        \n",
    "        # Estimate uncertainty (using model's feature importance as proxy)\n",
    "        # In production, use prediction intervals or quantile regression\n",
    "        uncertainty = abs(price_change) * 0.1  # 10% uncertainty estimate\n",
    "        \n",
    "        predictions['predicted_price'] = predicted_price\n",
    "        predictions['current_price'] = current_price\n",
    "        predictions['expected_change'] = price_change\n",
    "        predictions['expected_change_pct'] = price_change_pct\n",
    "        predictions['price_range_low'] = predicted_price - uncertainty\n",
    "        predictions['price_range_high'] = predicted_price + uncertainty\n",
    "        predictions['range_span'] = uncertainty * 2\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Make predictions\n",
    "if 'direction_model' in locals() and direction_model is not None:\n",
    "    if 'X' in locals() and X is not None and len(X) > 0:\n",
    "        latest_features = X[-1]  # Use most recent data point\n",
    "        current_price_val = current_gold_data.get('current_price', df_processed[price_col].iloc[-1] if 'df_processed' in locals() and price_col in df_processed.columns else 2000.0)\n",
    "        \n",
    "        predictions = predict_gold_price(\n",
    "            direction_model, direction_scaler,\n",
    "            range_model if 'range_model' in locals() else None,\n",
    "            range_scaler if 'range_scaler' in locals() else None,\n",
    "            latest_features,\n",
    "            current_price_val\n",
    "        )\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"GOLD PRICE PREDICTION RESULTS\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        if 'direction' in predictions:\n",
    "            print(f\"\\nDirection Prediction: {predictions['direction']}\")\n",
    "            print(f\"Confidence: {predictions['direction_confidence']:.2f}%\")\n",
    "            print(f\"  - Up Probability: {predictions['up_probability']:.2f}%\")\n",
    "            print(f\"  - Down Probability: {predictions['down_probability']:.2f}%\")\n",
    "        \n",
    "        if 'predicted_price' in predictions:\n",
    "            print(f\"\\nPrice Prediction:\")\n",
    "            print(f\"  Current Price: ${predictions['current_price']:.2f}/oz\")\n",
    "            print(f\"  Predicted Price: ${predictions['predicted_price']:.2f}/oz\")\n",
    "            print(f\"  Expected Change: ${predictions['expected_change']:.2f} ({predictions['expected_change_pct']:+.2f}%)\")\n",
    "            print(f\"\\nPredicted Price Range:\")\n",
    "            print(f\"  Low: ${predictions['price_range_low']:.2f}/oz\")\n",
    "            print(f\"  High: ${predictions['price_range_high']:.2f}/oz\")\n",
    "            print(f\"  Range Span: ${predictions['range_span']:.2f}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "    else:\n",
    "        print(\"No features available for prediction\")\n",
    "else:\n",
    "    print(\"Please train the models first\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize gold price trends\n",
    "if 'df_processed' in locals() and price_col and date_col:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Plot 1: Price over time\n",
    "    axes[0, 0].plot(df_processed[date_col], df_processed[price_col], linewidth=2)\n",
    "    axes[0, 0].set_title('Gold Price Over Time', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Date')\n",
    "    axes[0, 0].set_ylabel('Price (USD/oz)')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add prediction point if available\n",
    "    if 'predictions' in locals() and 'predicted_price' in predictions:\n",
    "        last_date = df_processed[date_col].iloc[-1]\n",
    "        next_date = last_date + pd.Timedelta(days=1)\n",
    "        axes[0, 0].plot(next_date, predictions['predicted_price'], 'ro', markersize=10, label='Prediction')\n",
    "        axes[0, 0].errorbar(next_date, predictions['predicted_price'], \n",
    "                           yerr=[[predictions['predicted_price'] - predictions['price_range_low']],\n",
    "                                 [predictions['price_range_high'] - predictions['predicted_price']]],\n",
    "                           fmt='ro', capsize=5, label='Prediction Range')\n",
    "        axes[0, 0].legend()\n",
    "    \n",
    "    # Plot 2: Price changes\n",
    "    if 'price_change_pct' in df_processed.columns:\n",
    "        axes[0, 1].plot(df_processed[date_col], df_processed['price_change_pct'], alpha=0.7)\n",
    "        axes[0, 1].axhline(y=0, color='r', linestyle='--', alpha=0.5)\n",
    "        axes[0, 1].set_title('Price Change Percentage', fontsize=14, fontweight='bold')\n",
    "        axes[0, 1].set_xlabel('Date')\n",
    "        axes[0, 1].set_ylabel('Change (%)')\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Moving averages\n",
    "    if 'ma_7' in df_processed.columns and 'ma_30' in df_processed.columns:\n",
    "        axes[1, 0].plot(df_processed[date_col], df_processed[price_col], label='Price', alpha=0.7)\n",
    "        axes[1, 0].plot(df_processed[date_col], df_processed['ma_7'], label='MA 7', linewidth=2)\n",
    "        axes[1, 0].plot(df_processed[date_col], df_processed['ma_30'], label='MA 30', linewidth=2)\n",
    "        axes[1, 0].set_title('Price with Moving Averages', fontsize=14, fontweight='bold')\n",
    "        axes[1, 0].set_xlabel('Date')\n",
    "        axes[1, 0].set_ylabel('Price (USD/oz)')\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: News sentiment and price indicators\n",
    "    if 'news_df' in locals() and not news_df.empty and 'sentiment_stats' in locals():\n",
    "        # Create combined sentiment visualization\n",
    "        rise_fall_counts = [\n",
    "            sentiment_stats.get('rise_indicator_count', 0),\n",
    "            sentiment_stats.get('fall_indicator_count', 0)\n",
    "        ]\n",
    "        labels = ['Rise Indicators', 'Fall Indicators']\n",
    "        colors = ['green', 'red']\n",
    "        axes[1, 1].bar(labels, rise_fall_counts, color=colors, alpha=0.7)\n",
    "        axes[1, 1].set_title('News Price Direction Indicators', fontsize=14, fontweight='bold')\n",
    "        axes[1, 1].set_ylabel('Number of News Items')\n",
    "        axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Add combined sentiment score as text\n",
    "        combined_sent = sentiment_stats.get('avg_combined_sentiment', 0.0)\n",
    "        if combined_sent > 0.1:\n",
    "            signal_text = 'RISE Signal'\n",
    "            signal_color = 'green'\n",
    "        elif combined_sent < -0.1:\n",
    "            signal_text = 'FALL Signal'\n",
    "            signal_color = 'red'\n",
    "        else:\n",
    "            signal_text = 'NEUTRAL'\n",
    "            signal_color = 'gray'\n",
    "        \n",
    "        max_count = max(rise_fall_counts) if rise_fall_counts and max(rise_fall_counts) > 0 else 1\n",
    "        axes[1, 1].text(0.5, max_count * 0.9, f'Signal: {signal_text}', \n",
    "                       ha='center', fontsize=12, fontweight='bold', color=signal_color,\n",
    "                       transform=axes[1, 1].transData)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Data not available for visualization\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Notes and Next Steps\n",
    "\n",
    "### API Configuration:\n",
    "- **Alpha Vantage**: Used for real-time gold price data (API key configured in Configuration section)\n",
    "- **Google RSS**: Used for news sentiment analysis with gold-specific price indicators\n",
    "\n",
    "### Model Improvements:\n",
    "- Use more sophisticated models (LSTM, XGBoost, etc.)\n",
    "- Implement prediction intervals for better uncertainty estimation\n",
    "- Add more features (economic indicators, other commodity prices)\n",
    "- Implement time-series cross-validation\n",
    "- Add ensemble methods\n",
    "- Enhance keyword detection for news analysis\n",
    "\n",
    "### Data Updates:\n",
    "- Set up scheduled runs to fetch latest news and API prices\n",
    "- Implement real-time monitoring\n",
    "- Create alerts for significant price movements\n",
    "- Expand keyword vocabulary for better price direction prediction\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
