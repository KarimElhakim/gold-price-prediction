{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gold Price Prediction with News Integration\n",
    "\n",
    "This notebook predicts gold price direction (up/down) and price range using:\n",
    "- Historical gold price data from Kaggle\n",
    "- Google RSS news feeds for latest news sentiment\n",
    "- Real-time gold price API for current prices\n",
    "\n",
    "## Prediction Goals\n",
    "1. Predict whether gold price will go UP or DOWN\n",
    "2. Predict the price range/amount of change\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Configuration\n",
    "\n",
    "Set your Kaggle API token here (or use environment variables in Colab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "KAGGLE_API_TOKEN = \"KGAT_b352cb91c46b038224e3d90adb8d8c32\"\n",
    "ALPHA_VANTAGE_API_KEY = \"EF6488BOEZN0B69R\"\n",
    "\n",
    "# Set environment variable for Kaggle\n",
    "import os\n",
    "os.environ['KAGGLE_API_TOKEN'] = KAGGLE_API_TOKEN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Setup and Installation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install required packages\n",
    "!pip install kagglehub pandas numpy scikit-learn matplotlib seaborn feedparser requests beautifulsoup4 textblob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Kaggle dataset using kagglehub\n",
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"sid321axn/gold-price-prediction-dataset\")\n",
    "print(\"Path to dataset files:\", path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For RSS feeds and news\n",
    "import feedparser\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from textblob import TextBlob\n",
    "\n",
    "# For API calls\n",
    "import json\n",
    "import time\n",
    "\n",
    "# For machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, classification_report, mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Explore Kaggle Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "# Adjust the path based on your downloaded dataset structure\n",
    "dataset_path = path\n",
    "print(f\"Dataset located at: {dataset_path}\")\n",
    "\n",
    "# List files in the dataset\n",
    "if os.path.exists(dataset_path):\n",
    "    files = os.listdir(dataset_path)\n",
    "    print(\"Files in dataset:\", files)\n",
    "    \n",
    "    # Load the main CSV file (adjust filename as needed)\n",
    "    csv_files = [f for f in files if f.endswith('.csv')]\n",
    "    if csv_files:\n",
    "        df_gold = pd.read_csv(os.path.join(dataset_path, csv_files[0]))\n",
    "        print(f\"\\nLoaded: {csv_files[0]}\")\n",
    "        print(f\"Shape: {df_gold.shape}\")\n",
    "        print(f\"\\nFirst few rows:\")\n",
    "        print(df_gold.head())\n",
    "        print(f\"\\nColumn names: {df_gold.columns.tolist()}\")\n",
    "        print(f\"\\nData types:\\n{df_gold.dtypes}\")\n",
    "        print(f\"\\nBasic statistics:\\n{df_gold.describe()}\")\n",
    "    else:\n",
    "        print(\"No CSV files found in dataset\")\n",
    "else:\n",
    "    print(\"Dataset path not found. Please check the path.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Google RSS News Integration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news_sentiment(query=\"gold price\", max_results=20):\n",
    "    \"\"\"\n",
    "    Fetch news from Google RSS feeds and analyze sentiment\n",
    "    \"\"\"\n",
    "    # Google News RSS feed URL\n",
    "    rss_url = f\"https://news.google.com/rss/search?q={query}&hl=en-US&gl=US&ceid=US:en\"\n",
    "    \n",
    "    try:\n",
    "        feed = feedparser.parse(rss_url)\n",
    "        news_items = []\n",
    "        \n",
    "        for entry in feed.entries[:max_results]:\n",
    "            title = entry.get('title', '')\n",
    "            summary = entry.get('summary', '')\n",
    "            published = entry.get('published', '')\n",
    "            link = entry.get('link', '')\n",
    "            \n",
    "            # Combine title and summary for sentiment analysis\n",
    "            text = f\"{title} {summary}\"\n",
    "            blob = TextBlob(text)\n",
    "            sentiment_score = blob.sentiment.polarity  # Range: -1 to 1\n",
    "            \n",
    "            news_items.append({\n",
    "                'title': title,\n",
    "                'summary': summary,\n",
    "                'published': published,\n",
    "                'link': link,\n",
    "                'sentiment': sentiment_score\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(news_items)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching news: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def aggregate_news_sentiment(news_df):\n",
    "    \"\"\"\n",
    "    Aggregate news sentiment for a given day/period\n",
    "    \"\"\"\n",
    "    if news_df.empty:\n",
    "        return {\n",
    "            'avg_sentiment': 0.0,\n",
    "            'positive_count': 0,\n",
    "            'negative_count': 0,\n",
    "            'news_count': 0\n",
    "        }\n",
    "    \n",
    "    avg_sentiment = news_df['sentiment'].mean()\n",
    "    positive_count = (news_df['sentiment'] > 0.1).sum()\n",
    "    negative_count = (news_df['sentiment'] < -0.1).sum()\n",
    "    \n",
    "    return {\n",
    "        'avg_sentiment': avg_sentiment,\n",
    "        'positive_count': positive_count,\n",
    "        'negative_count': negative_count,\n",
    "        'news_count': len(news_df)\n",
    "    }\n",
    "\n",
    "# Fetch current gold-related news\n",
    "print(\"Fetching latest gold price news...\")\n",
    "news_df = get_news_sentiment(\"gold price OR gold market OR gold trading\", max_results=30)\n",
    "print(f\"\\nFetched {len(news_df)} news items\")\n",
    "\n",
    "if not news_df.empty:\n",
    "    print(\"\\nSample news items:\")\n",
    "    print(news_df[['title', 'sentiment']].head(10))\n",
    "    \n",
    "    # Aggregate sentiment\n",
    "    sentiment_stats = aggregate_news_sentiment(news_df)\n",
    "    print(f\"\\nNews Sentiment Statistics:\")\n",
    "    print(f\"Average Sentiment: {sentiment_stats['avg_sentiment']:.3f}\")\n",
    "    print(f\"Positive News: {sentiment_stats['positive_count']}\")\n",
    "    print(f\"Negative News: {sentiment_stats['negative_count']}\")\n",
    "    print(f\"Total News: {sentiment_stats['news_count']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Free Gold Price API Integration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gold_price_api(api_key=None):\n",
    "    \"\"\"\n",
    "    Fetch current gold price using free APIs\n",
    "    Options: Metal-API, Alpha Vantage, or GoldAPI.io (free tier available)\n",
    "    \"\"\"\n",
    "    current_price = None\n",
    "    price_data = {}\n",
    "    \n",
    "    # Method 1: Metal-API (Free tier: 200 requests/month, no API key needed for basic)\n",
    "    try:\n",
    "        url = \"https://api.metalpriceapi.com/v1/latest?api_key=YOUR_API_KEY&base=USD&currencies=XAU\"\n",
    "        # Alternative: Use exchangerate-api.com for free gold prices\n",
    "        url_alt = \"https://api.exchangerate-api.com/v4/latest/XAU\"\n",
    "        \n",
    "        response = requests.get(url_alt, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            # Note: This API structure may vary, adjust accordingly\n",
    "            current_price = data.get('rates', {}).get('USD', None)\n",
    "            if current_price:\n",
    "                current_price = 1 / current_price  # Convert from XAU to USD per ounce\n",
    "            price_data['source'] = 'exchangerate-api'\n",
    "    except Exception as e:\n",
    "        print(f\"Method 1 failed: {e}\")\n",
    "    \n",
    "    # Method 2: GoldPrice.org API (free, no key required)\n",
    "    if current_price is None:\n",
    "        try:\n",
    "            url = \"https://api.goldprice.org/gpapi/v2/quotes/USD\"\n",
    "            headers = {\n",
    "                'User-Agent': 'Mozilla/5.0',\n",
    "                'Accept': 'application/json'\n",
    "            }\n",
    "            response = requests.get(url, headers=headers, timeout=10)\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                # Parse response based on actual API structure\n",
    "                current_price = data.get('price', None)\n",
    "                price_data['source'] = 'goldprice.org'\n",
    "        except Exception as e:\n",
    "            print(f\"Method 2 failed: {e}\")\n",
    "    \n",
    "    # Method 3: Alpha Vantage (free tier available)\n",
    "    if current_price is None and api_key:\n",
    "        try:\n",
    "            url = f\"https://www.alphavantage.co/query?function=CURRENCY_EXCHANGE_RATE&from_currency=XAU&to_currency=USD&apikey={api_key}\"\n",
    "            response = requests.get(url, timeout=10)\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                rate = data.get('Realtime Currency Exchange Rate', {})\n",
    "                current_price = float(rate.get('5. Exchange Rate', 0))\n",
    "                price_data['source'] = 'alpha-vantage'\n",
    "        except Exception as e:\n",
    "            print(f\"Method 3 failed: {e}\")\n",
    "    \n",
    "    # Use the API key from configuration if available\n",
    "    if current_price is None and 'ALPHA_VANTAGE_API_KEY' in globals() and ALPHA_VANTAGE_API_KEY:\n",
    "        try:\n",
    "            url = f\"https://www.alphavantage.co/query?function=CURRENCY_EXCHANGE_RATE&from_currency=XAU&to_currency=USD&apikey={ALPHA_VANTAGE_API_KEY}\"\n",
    "            response = requests.get(url, timeout=10)\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                rate = data.get('Realtime Currency Exchange Rate', {})\n",
    "                current_price = float(rate.get('5. Exchange Rate', 0))\n",
    "                price_data['source'] = 'alpha-vantage'\n",
    "        except Exception as e:\n",
    "            print(f\"Method 3 (from config) failed: {e}\")\n",
    "    \n",
    "    if current_price:\n",
    "        price_data['current_price'] = current_price\n",
    "        price_data['timestamp'] = datetime.now().isoformat()\n",
    "        print(f\"Current Gold Price (USD/oz): ${current_price:.2f} from {price_data.get('source', 'unknown')}\")\n",
    "    else:\n",
    "        print(\"Warning: Could not fetch current gold price from APIs\")\n",
    "        # Use a placeholder or last known price\n",
    "        current_price = 2000.0  # Placeholder\n",
    "        price_data['current_price'] = current_price\n",
    "        price_data['source'] = 'placeholder'\n",
    "    \n",
    "    return price_data\n",
    "\n",
    "# Fetch current gold price\n",
    "print(\"Fetching current gold price...\")\n",
    "current_gold_data = get_gold_price_api(api_key=ALPHA_VANTAGE_API_KEY if 'ALPHA_VANTAGE_API_KEY' in globals() else None)\n",
    "print(f\"\\nGold Price Data: {current_gold_data}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_gold_data(df):\n",
    "    \"\"\"\n",
    "    Preprocess the gold price dataset\n",
    "    \"\"\"\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    # Convert date column to datetime (adjust column name as needed)\n",
    "    date_col = None\n",
    "    for col in df_processed.columns:\n",
    "        if 'date' in col.lower() or 'time' in col.lower():\n",
    "            date_col = col\n",
    "            break\n",
    "    \n",
    "    if date_col:\n",
    "        df_processed[date_col] = pd.to_datetime(df_processed[date_col], errors='coerce')\n",
    "        df_processed = df_processed.sort_values(date_col).reset_index(drop=True)\n",
    "    \n",
    "    # Identify price column (usually contains 'price', 'close', or 'value')\n",
    "    price_col = None\n",
    "    for col in df_processed.columns:\n",
    "        if 'price' in col.lower() or 'close' in col.lower() or 'value' in col.lower():\n",
    "            price_col = col\n",
    "            break\n",
    "    \n",
    "    # Create features\n",
    "    if price_col and df_processed[price_col].dtype in ['float64', 'int64']:\n",
    "        # Price change\n",
    "        df_processed['price_change'] = df_processed[price_col].diff()\n",
    "        df_processed['price_change_pct'] = df_processed[price_col].pct_change() * 100\n",
    "        \n",
    "        # Moving averages\n",
    "        df_processed['ma_7'] = df_processed[price_col].rolling(window=7).mean()\n",
    "        df_processed['ma_30'] = df_processed[price_col].rolling(window=30).mean()\n",
    "        \n",
    "        # Price volatility\n",
    "        df_processed['volatility'] = df_processed[price_col].rolling(window=7).std()\n",
    "        \n",
    "        # Price direction (target for classification)\n",
    "        df_processed['direction'] = (df_processed[price_col].shift(-1) > df_processed[price_col]).astype(int)\n",
    "        \n",
    "        # Price range for next period (target for regression)\n",
    "        df_processed['next_price'] = df_processed[price_col].shift(-1)\n",
    "        # Create a temporary dataframe for min/max calculation\n",
    "        temp_df = pd.DataFrame({\n",
    "            'current': df_processed[price_col],\n",
    "            'next': df_processed['next_price']\n",
    "        })\n",
    "        df_processed['price_range_low'] = temp_df[['current', 'next']].min(axis=1)\n",
    "        df_processed['price_range_high'] = temp_df[['current', 'next']].max(axis=1)\n",
    "        df_processed['price_range'] = df_processed['price_range_high'] - df_processed['price_range_low']\n",
    "    \n",
    "    # Handle missing values - use forward and backward fill\n",
    "    df_processed = df_processed.fillna(method='bfill').fillna(method='ffill')\n",
    "    # Drop any remaining NaN rows\n",
    "    df_processed = df_processed.dropna()\n",
    "    \n",
    "    return df_processed, price_col, date_col\n",
    "\n",
    "# Preprocess the dataset\n",
    "if 'df_gold' in locals() and not df_gold.empty:\n",
    "    df_processed, price_col, date_col = preprocess_gold_data(df_gold)\n",
    "    print(f\"Processed dataset shape: {df_processed.shape}\")\n",
    "    print(f\"Price column: {price_col}\")\n",
    "    print(f\"Date column: {date_col}\")\n",
    "    print(f\"\\nProcessed data head:\")\n",
    "    print(df_processed.head())\n",
    "else:\n",
    "    print(\"Please load the dataset first in section 3\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Engineering with News and API Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_matrix(df_processed, news_sentiment=None, current_api_price=None):\n",
    "    \"\"\"\n",
    "    Create feature matrix combining historical data, news sentiment, and API price\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    \n",
    "    # Historical price features\n",
    "    if price_col and price_col in df_processed.columns:\n",
    "        feature_cols = [\n",
    "            price_col,\n",
    "            'price_change', 'price_change_pct',\n",
    "            'ma_7', 'ma_30', 'volatility'\n",
    "        ]\n",
    "        \n",
    "        # Add available features\n",
    "        available_features = [col for col in feature_cols if col in df_processed.columns]\n",
    "        X = df_processed[available_features].values\n",
    "        \n",
    "        # Add news sentiment features (if available)\n",
    "        if news_sentiment:\n",
    "            sentiment_features = [\n",
    "                news_sentiment['avg_sentiment'],\n",
    "                news_sentiment['positive_count'],\n",
    "                news_sentiment['negative_count'],\n",
    "                news_sentiment['news_count']\n",
    "            ]\n",
    "            # Repeat sentiment for each row (or match by date if dates available)\n",
    "            sentiment_array = np.tile(sentiment_features, (len(X), 1))\n",
    "            X = np.hstack([X, sentiment_array])\n",
    "        \n",
    "        # Add current API price features (if available)\n",
    "        if current_api_price and 'current_price' in current_api_price:\n",
    "            api_price = current_api_price['current_price']\n",
    "            # Compare with last historical price\n",
    "            last_price = df_processed[price_col].iloc[-1] if len(df_processed) > 0 else api_price\n",
    "            price_diff = api_price - last_price\n",
    "            price_diff_pct = (price_diff / last_price) * 100\n",
    "            \n",
    "            api_features = np.array([[api_price, price_diff, price_diff_pct]])\n",
    "            api_features_tiled = np.tile(api_features, (len(X), 1))\n",
    "            X = np.hstack([X, api_features_tiled])\n",
    "        \n",
    "        return X, available_features\n",
    "    \n",
    "    return None, []\n",
    "\n",
    "# Create feature matrix\n",
    "if 'df_processed' in locals() and not df_processed.empty:\n",
    "    X, feature_names = create_feature_matrix(\n",
    "        df_processed,\n",
    "        news_sentiment=sentiment_stats if 'sentiment_stats' in locals() else None,\n",
    "        current_api_price=current_gold_data if 'current_gold_data' in locals() else None\n",
    "    )\n",
    "    \n",
    "    if X is not None:\n",
    "        print(f\"Feature matrix shape: {X.shape}\")\n",
    "        print(f\"Feature names: {feature_names}\")\n",
    "        print(f\"\\nFeature matrix sample:\")\n",
    "        print(X[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Training - Direction Prediction (Up/Down)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_direction_model(X, y_direction):\n",
    "    \"\"\"\n",
    "    Train a model to predict price direction (up/down)\n",
    "    \"\"\"\n",
    "    # Remove rows where target is NaN\n",
    "    valid_mask = ~np.isnan(y_direction)\n",
    "    X_clean = X[valid_mask]\n",
    "    y_clean = y_direction[valid_mask].astype(int)\n",
    "    \n",
    "    if len(X_clean) == 0:\n",
    "        print(\"No valid data for training\")\n",
    "        return None, None, None\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_clean, y_clean, test_size=0.2, random_state=42, stratify=y_clean\n",
    "    )\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Train Random Forest Classifier\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Direction Prediction Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['Down', 'Up']))\n",
    "    \n",
    "    # Feature importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': feature_names[:len(model.feature_importances_)] if 'feature_names' in globals() else [f'feature_{i}' for i in range(len(model.feature_importances_))],\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(f\"\\nTop Features:\")\n",
    "    print(feature_importance.head(10))\n",
    "    \n",
    "    return model, scaler, feature_importance\n",
    "\n",
    "# Train direction model\n",
    "if 'X' in locals() and X is not None and 'df_processed' in locals():\n",
    "    if 'direction' in df_processed.columns:\n",
    "        y_direction = df_processed['direction'].values\n",
    "        \n",
    "        direction_model, direction_scaler, feature_importance = train_direction_model(X, y_direction)\n",
    "        \n",
    "        if direction_model is not None:\n",
    "            print(\"\\nDirection model trained successfully!\")\n",
    "    else:\n",
    "        print(\"Direction column not found. Creating it...\")\n",
    "        # Create direction column if it doesn't exist\n",
    "        if price_col in df_processed.columns:\n",
    "            df_processed['direction'] = (df_processed[price_col].shift(-1) > df_processed[price_col]).astype(int)\n",
    "            y_direction = df_processed['direction'].values\n",
    "            direction_model, direction_scaler, feature_importance = train_direction_model(X, y_direction)\n",
    "else:\n",
    "    print(\"Please complete data preprocessing first\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Training - Price Range Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_range_model(X, y_price):\n",
    "    \"\"\"\n",
    "    Train a model to predict price range (how much the price will change)\n",
    "    \"\"\"\n",
    "    # Remove rows where target is NaN\n",
    "    valid_mask = ~np.isnan(y_price)\n",
    "    X_clean = X[valid_mask]\n",
    "    y_clean = y_price[valid_mask]\n",
    "    \n",
    "    if len(X_clean) == 0:\n",
    "        print(\"No valid data for training\")\n",
    "        return None, None, None\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_clean, y_clean, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Train Random Forest Regressor for price prediction\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    print(f\"Price Range Prediction:\")\n",
    "    print(f\"Mean Absolute Error: ${mae:.2f}\")\n",
    "    print(f\"Root Mean Squared Error: ${rmse:.2f}\")\n",
    "    print(f\"Mean Actual Price: ${y_test.mean():.2f}\")\n",
    "    print(f\"Mean Predicted Price: ${y_pred.mean():.2f}\")\n",
    "    \n",
    "    return model, scaler, {'mae': mae, 'rmse': rmse}\n",
    "\n",
    "# Train range model\n",
    "if 'X' in locals() and X is not None and 'df_processed' in locals():\n",
    "    if 'next_price' in df_processed.columns:\n",
    "        y_price = df_processed['next_price'].values\n",
    "        \n",
    "        range_model, range_scaler, range_metrics = train_range_model(X, y_price)\n",
    "        \n",
    "        if range_model is not None:\n",
    "            print(\"\\nPrice range model trained successfully!\")\n",
    "    else:\n",
    "        print(\"Next price column not found. Please check data preprocessing.\")\n",
    "else:\n",
    "    print(\"Please complete data preprocessing first\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Make Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_gold_price(direction_model, direction_scaler, range_model, range_scaler, \n",
    "                       latest_features, current_price):\n",
    "    \"\"\"\n",
    "    Make predictions for gold price direction and range\n",
    "    \"\"\"\n",
    "    predictions = {}\n",
    "    \n",
    "    # Predict direction\n",
    "    if direction_model is not None and direction_scaler is not None:\n",
    "        # Use the latest features for prediction\n",
    "        latest_features_scaled = direction_scaler.transform([latest_features])\n",
    "        direction_proba = direction_model.predict_proba(latest_features_scaled)[0]\n",
    "        direction_pred = direction_model.predict(latest_features_scaled)[0]\n",
    "        \n",
    "        predictions['direction'] = 'UP' if direction_pred == 1 else 'DOWN'\n",
    "        predictions['direction_confidence'] = max(direction_proba) * 100\n",
    "        predictions['up_probability'] = direction_proba[1] * 100\n",
    "        predictions['down_probability'] = direction_proba[0] * 100\n",
    "    \n",
    "    # Predict price range\n",
    "    if range_model is not None and range_scaler is not None:\n",
    "        latest_features_scaled = range_scaler.transform([latest_features])\n",
    "        predicted_price = range_model.predict(latest_features_scaled)[0]\n",
    "        \n",
    "        # Calculate range\n",
    "        price_change = predicted_price - current_price\n",
    "        price_change_pct = (price_change / current_price) * 100\n",
    "        \n",
    "        # Estimate uncertainty (using model's feature importance as proxy)\n",
    "        # In production, use prediction intervals or quantile regression\n",
    "        uncertainty = abs(price_change) * 0.1  # 10% uncertainty estimate\n",
    "        \n",
    "        predictions['predicted_price'] = predicted_price\n",
    "        predictions['current_price'] = current_price\n",
    "        predictions['expected_change'] = price_change\n",
    "        predictions['expected_change_pct'] = price_change_pct\n",
    "        predictions['price_range_low'] = predicted_price - uncertainty\n",
    "        predictions['price_range_high'] = predicted_price + uncertainty\n",
    "        predictions['range_span'] = uncertainty * 2\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Make predictions\n",
    "if 'direction_model' in locals() and direction_model is not None:\n",
    "    if 'X' in locals() and X is not None and len(X) > 0:\n",
    "        latest_features = X[-1]  # Use most recent data point\n",
    "        current_price_val = current_gold_data.get('current_price', df_processed[price_col].iloc[-1] if 'df_processed' in locals() and price_col in df_processed.columns else 2000.0)\n",
    "        \n",
    "        predictions = predict_gold_price(\n",
    "            direction_model, direction_scaler,\n",
    "            range_model if 'range_model' in locals() else None,\n",
    "            range_scaler if 'range_scaler' in locals() else None,\n",
    "            latest_features,\n",
    "            current_price_val\n",
    "        )\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"GOLD PRICE PREDICTION RESULTS\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        if 'direction' in predictions:\n",
    "            print(f\"\\nDirection Prediction: {predictions['direction']}\")\n",
    "            print(f\"Confidence: {predictions['direction_confidence']:.2f}%\")\n",
    "            print(f\"  - Up Probability: {predictions['up_probability']:.2f}%\")\n",
    "            print(f\"  - Down Probability: {predictions['down_probability']:.2f}%\")\n",
    "        \n",
    "        if 'predicted_price' in predictions:\n",
    "            print(f\"\\nPrice Prediction:\")\n",
    "            print(f\"  Current Price: ${predictions['current_price']:.2f}/oz\")\n",
    "            print(f\"  Predicted Price: ${predictions['predicted_price']:.2f}/oz\")\n",
    "            print(f\"  Expected Change: ${predictions['expected_change']:.2f} ({predictions['expected_change_pct']:+.2f}%)\")\n",
    "            print(f\"\\nPredicted Price Range:\")\n",
    "            print(f\"  Low: ${predictions['price_range_low']:.2f}/oz\")\n",
    "            print(f\"  High: ${predictions['price_range_high']:.2f}/oz\")\n",
    "            print(f\"  Range Span: ${predictions['range_span']:.2f}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "    else:\n",
    "        print(\"No features available for prediction\")\n",
    "else:\n",
    "    print(\"Please train the models first\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize gold price trends\n",
    "if 'df_processed' in locals() and price_col and date_col:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Plot 1: Price over time\n",
    "    axes[0, 0].plot(df_processed[date_col], df_processed[price_col], linewidth=2)\n",
    "    axes[0, 0].set_title('Gold Price Over Time', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Date')\n",
    "    axes[0, 0].set_ylabel('Price (USD/oz)')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add prediction point if available\n",
    "    if 'predictions' in locals() and 'predicted_price' in predictions:\n",
    "        last_date = df_processed[date_col].iloc[-1]\n",
    "        next_date = last_date + pd.Timedelta(days=1)\n",
    "        axes[0, 0].plot(next_date, predictions['predicted_price'], 'ro', markersize=10, label='Prediction')\n",
    "        axes[0, 0].errorbar(next_date, predictions['predicted_price'], \n",
    "                           yerr=[[predictions['predicted_price'] - predictions['price_range_low']],\n",
    "                                 [predictions['price_range_high'] - predictions['predicted_price']]],\n",
    "                           fmt='ro', capsize=5, label='Prediction Range')\n",
    "        axes[0, 0].legend()\n",
    "    \n",
    "    # Plot 2: Price changes\n",
    "    if 'price_change_pct' in df_processed.columns:\n",
    "        axes[0, 1].plot(df_processed[date_col], df_processed['price_change_pct'], alpha=0.7)\n",
    "        axes[0, 1].axhline(y=0, color='r', linestyle='--', alpha=0.5)\n",
    "        axes[0, 1].set_title('Price Change Percentage', fontsize=14, fontweight='bold')\n",
    "        axes[0, 1].set_xlabel('Date')\n",
    "        axes[0, 1].set_ylabel('Change (%)')\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Moving averages\n",
    "    if 'ma_7' in df_processed.columns and 'ma_30' in df_processed.columns:\n",
    "        axes[1, 0].plot(df_processed[date_col], df_processed[price_col], label='Price', alpha=0.7)\n",
    "        axes[1, 0].plot(df_processed[date_col], df_processed['ma_7'], label='MA 7', linewidth=2)\n",
    "        axes[1, 0].plot(df_processed[date_col], df_processed['ma_30'], label='MA 30', linewidth=2)\n",
    "        axes[1, 0].set_title('Price with Moving Averages', fontsize=14, fontweight='bold')\n",
    "        axes[1, 0].set_xlabel('Date')\n",
    "        axes[1, 0].set_ylabel('Price (USD/oz)')\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: News sentiment over time (if multiple data points available)\n",
    "    if 'news_df' in locals() and not news_df.empty:\n",
    "        sentiment_counts = [sentiment_stats['positive_count'], sentiment_stats['negative_count']]\n",
    "        labels = ['Positive', 'Negative']\n",
    "        colors = ['green', 'red']\n",
    "        axes[1, 1].bar(labels, sentiment_counts, color=colors, alpha=0.7)\n",
    "        axes[1, 1].set_title('Current News Sentiment Distribution', fontsize=14, fontweight='bold')\n",
    "        axes[1, 1].set_ylabel('Number of News Items')\n",
    "        axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Data not available for visualization\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Notes and Next Steps\n",
    "\n",
    "### API Keys Setup (if needed):\n",
    "1. **Metal-API**: Get free API key from https://metalpriceapi.com\n",
    "2. **Alpha Vantage**: Get free API key from https://www.alphavantage.co/support/#api-key\n",
    "3. **GoldAPI.io**: Free tier available at https://www.goldapi.io\n",
    "\n",
    "### To use API keys in Google Colab:\n",
    "1. Go to: Runtime > Change runtime type > Environment variables\n",
    "2. Or use Colab's secret manager\n",
    "3. Or set in notebook: `os.environ['API_KEY'] = 'your_key'`\n",
    "\n",
    "### Model Improvements:\n",
    "- Use more sophisticated models (LSTM, XGBoost, etc.)\n",
    "- Implement prediction intervals for better uncertainty estimation\n",
    "- Add more features (economic indicators, other commodity prices)\n",
    "- Implement time-series cross-validation\n",
    "- Add ensemble methods\n",
    "\n",
    "### Data Updates:\n",
    "- Set up scheduled runs to fetch latest news and API prices\n",
    "- Implement real-time monitoring\n",
    "- Create alerts for significant price movements\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}