{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gold Price Prediction with News Integration\n",
    "\n",
    "This notebook predicts gold price direction (up/down) and price range using:\n",
    "- Historical gold price data from Kaggle\n",
    "- Google RSS news feeds for latest news sentiment\n",
    "- Real-time gold price API for current prices\n",
    "\n",
    "## Prediction Goals\n",
    "1. Predict whether gold price will go UP or DOWN\n",
    "2. Predict the price range/amount of change\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Configuration\n",
    "\n",
    "Set your Kaggle API token here (or use environment variables in Colab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "KAGGLE_API_TOKEN = \"KGAT_b352cb91c46b038224e3d90adb8d8c32\"\n",
    "ALPHA_VANTAGE_API_KEY = \"EF6488BOEZN0B69R\"\n",
    "\n",
    "# Set environment variable for Kaggle\n",
    "import os\n",
    "os.environ['KAGGLE_API_TOKEN'] = KAGGLE_API_TOKEN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Setup and Installation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install required packages\n",
    "!pip install kagglehub pandas numpy scikit-learn matplotlib seaborn feedparser requests beautifulsoup4 textblob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/sid321axn/gold-price-prediction-dataset?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 371k/371k [00:00<00:00, 665kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n",
      "Path to dataset files: C:\\Users\\miste\\.cache\\kagglehub\\datasets\\sid321axn\\gold-price-prediction-dataset\\versions\\1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Download Kaggle dataset using kagglehub\n",
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"sid321axn/gold-price-prediction-dataset\")\n",
    "print(\"Path to dataset files:\", path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For RSS feeds and news\n",
    "import feedparser\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from textblob import TextBlob\n",
    "\n",
    "# For API calls\n",
    "import json\n",
    "import time\n",
    "\n",
    "# For machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, classification_report, mean_absolute_error, mean_squared_error\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import joblib\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Explore Kaggle Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset located at: C:\\Users\\miste\\.cache\\kagglehub\\datasets\\sid321axn\\gold-price-prediction-dataset\\versions\\1\n",
      "Files in dataset: ['FINAL_USO.csv']\n",
      "\n",
      "Loaded: FINAL_USO.csv\n",
      "Shape: (1718, 81)\n",
      "\n",
      "First few rows:\n",
      "         Date        Open        High         Low       Close   Adj Close  \\\n",
      "0  2011-12-15  154.740005  154.949997  151.710007  152.330002  152.330002   \n",
      "1  2011-12-16  154.309998  155.369995  153.899994  155.229996  155.229996   \n",
      "2  2011-12-19  155.479996  155.860001  154.360001  154.869995  154.869995   \n",
      "3  2011-12-20  156.820007  157.429993  156.580002  156.979996  156.979996   \n",
      "4  2011-12-21  156.979996  157.529999  156.130005  157.160004  157.160004   \n",
      "\n",
      "     Volume     SP_open     SP_high      SP_low  ...    GDX_Low  GDX_Close  \\\n",
      "0  21521900  123.029999  123.199997  121.989998  ...  51.570000  51.680000   \n",
      "1  18124300  122.230003  122.949997  121.300003  ...  52.040001  52.680000   \n",
      "2  12547200  122.059998  122.320000  120.029999  ...  51.029999  51.169998   \n",
      "3   9136300  122.180000  124.139999  120.370003  ...  52.369999  52.990002   \n",
      "4  11996100  123.930000  124.360001  122.750000  ...  52.419998  52.959999   \n",
      "\n",
      "   GDX_Adj Close  GDX_Volume   USO_Open   USO_High    USO_Low  USO_Close  \\\n",
      "0      48.973877    20605600  36.900002  36.939999  36.049999  36.130001   \n",
      "1      49.921513    16285400  36.180000  36.500000  35.730000  36.270000   \n",
      "2      48.490578    15120200  36.389999  36.450001  35.930000  36.200001   \n",
      "3      50.215282    11644900  37.299999  37.610001  37.220001  37.560001   \n",
      "4      50.186852     8724300  37.669998  38.240002  37.520000  38.110001   \n",
      "\n",
      "   USO_Adj Close  USO_Volume  \n",
      "0      36.130001    12616700  \n",
      "1      36.270000    12578800  \n",
      "2      36.200001     7418200  \n",
      "3      37.560001    10041600  \n",
      "4      38.110001    10728000  \n",
      "\n",
      "[5 rows x 81 columns]\n",
      "\n",
      "Column names: ['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'SP_open', 'SP_high', 'SP_low', 'SP_close', 'SP_Ajclose', 'SP_volume', 'DJ_open', 'DJ_high', 'DJ_low', 'DJ_close', 'DJ_Ajclose', 'DJ_volume', 'EG_open', 'EG_high', 'EG_low', 'EG_close', 'EG_Ajclose', 'EG_volume', 'EU_Price', 'EU_open', 'EU_high', 'EU_low', 'EU_Trend', 'OF_Price', 'OF_Open', 'OF_High', 'OF_Low', 'OF_Volume', 'OF_Trend', 'OS_Price', 'OS_Open', 'OS_High', 'OS_Low', 'OS_Trend', 'SF_Price', 'SF_Open', 'SF_High', 'SF_Low', 'SF_Volume', 'SF_Trend', 'USB_Price', 'USB_Open', 'USB_High', 'USB_Low', 'USB_Trend', 'PLT_Price', 'PLT_Open', 'PLT_High', 'PLT_Low', 'PLT_Trend', 'PLD_Price', 'PLD_Open', 'PLD_High', 'PLD_Low', 'PLD_Trend', 'RHO_PRICE', 'USDI_Price', 'USDI_Open', 'USDI_High', 'USDI_Low', 'USDI_Volume', 'USDI_Trend', 'GDX_Open', 'GDX_High', 'GDX_Low', 'GDX_Close', 'GDX_Adj Close', 'GDX_Volume', 'USO_Open', 'USO_High', 'USO_Low', 'USO_Close', 'USO_Adj Close', 'USO_Volume']\n",
      "\n",
      "Data types:\n",
      "Date              object\n",
      "Open             float64\n",
      "High             float64\n",
      "Low              float64\n",
      "Close            float64\n",
      "                  ...   \n",
      "USO_High         float64\n",
      "USO_Low          float64\n",
      "USO_Close        float64\n",
      "USO_Adj Close    float64\n",
      "USO_Volume         int64\n",
      "Length: 81, dtype: object\n",
      "\n",
      "Basic statistics:\n",
      "              Open         High          Low        Close    Adj Close  \\\n",
      "count  1718.000000  1718.000000  1718.000000  1718.000000  1718.000000   \n",
      "mean    127.323434   127.854237   126.777695   127.319482   127.319482   \n",
      "std      17.526993    17.631189    17.396513    17.536269    17.536269   \n",
      "min     100.919998   100.989998   100.230003   100.500000   100.500000   \n",
      "25%     116.220001   116.540001   115.739998   116.052502   116.052502   \n",
      "50%     121.915001   122.325001   121.369999   121.795002   121.795002   \n",
      "75%     128.427494   129.087498   127.840001   128.470001   128.470001   \n",
      "max     173.199997   174.070007   172.919998   173.610001   173.610001   \n",
      "\n",
      "             Volume      SP_open      SP_high       SP_low     SP_close  ...  \\\n",
      "count  1.718000e+03  1718.000000  1718.000000  1718.000000  1718.000000  ...   \n",
      "mean   8.446327e+06   204.490023   205.372637   203.487014   204.491222  ...   \n",
      "std    4.920731e+06    43.831928    43.974644    43.618940    43.776999  ...   \n",
      "min    1.501600e+06   122.059998   122.320000   120.029999   120.290001  ...   \n",
      "25%    5.412925e+06   170.392498   170.962506   169.577499   170.397500  ...   \n",
      "50%    7.483900e+06   205.464996   206.459999   204.430000   205.529999  ...   \n",
      "75%    1.020795e+07   237.292500   237.722500   236.147503   236.889996  ...   \n",
      "max    9.380420e+07   293.089996   293.940002   291.809998   293.579987  ...   \n",
      "\n",
      "           GDX_Low    GDX_Close  GDX_Adj Close    GDX_Volume     USO_Open  \\\n",
      "count  1718.000000  1718.000000    1718.000000  1.718000e+03  1718.000000   \n",
      "mean     26.384575    26.715012      25.924624  4.356515e+07    22.113417   \n",
      "std      10.490908    10.603110       9.886570  2.909151e+07    11.431056   \n",
      "min      12.400000    12.470000      12.269618  4.729000e+06     7.820000   \n",
      "25%      20.355000    20.585000      20.180950  2.259968e+07    11.420000   \n",
      "50%      22.870001    23.054999      22.677604  3.730465e+07    16.450000   \n",
      "75%      26.797500    27.317500      26.478154  5.697055e+07    34.419998   \n",
      "max      56.770000    57.470001      54.617039  2.321536e+08    41.599998   \n",
      "\n",
      "          USO_High      USO_Low    USO_Close  USO_Adj Close    USO_Volume  \n",
      "count  1718.000000  1718.000000  1718.000000    1718.000000  1.718000e+03  \n",
      "mean     22.307148    21.904657    22.109051      22.109051  1.922313e+07  \n",
      "std      11.478671    11.373997    11.432787      11.432787  1.575743e+07  \n",
      "min       8.030000     7.670000     7.960000       7.960000  1.035100e+06  \n",
      "25%      11.500000    11.300000    11.392500      11.392500  6.229500e+06  \n",
      "50%      16.635001    16.040000    16.345000      16.345000  1.613015e+07  \n",
      "75%      34.667499    34.110000    34.417499      34.417499  2.672375e+07  \n",
      "max      42.299999    41.299999    42.009998      42.009998  1.102657e+08  \n",
      "\n",
      "[8 rows x 80 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "# Adjust the path based on your downloaded dataset structure\n",
    "dataset_path = path\n",
    "print(f\"Dataset located at: {dataset_path}\")\n",
    "\n",
    "# List files in the dataset\n",
    "if os.path.exists(dataset_path):\n",
    "    files = os.listdir(dataset_path)\n",
    "    print(\"Files in dataset:\", files)\n",
    "    \n",
    "    # Load the main CSV file (adjust filename as needed)\n",
    "    csv_files = [f for f in files if f.endswith('.csv')]\n",
    "    if csv_files:\n",
    "        df_gold = pd.read_csv(os.path.join(dataset_path, csv_files[0]))\n",
    "        print(f\"\\nLoaded: {csv_files[0]}\")\n",
    "        print(f\"Shape: {df_gold.shape}\")\n",
    "        print(f\"\\nFirst few rows:\")\n",
    "        print(df_gold.head())\n",
    "        print(f\"\\nColumn names: {df_gold.columns.tolist()}\")\n",
    "        print(f\"\\nData types:\\n{df_gold.dtypes}\")\n",
    "        print(f\"\\nBasic statistics:\\n{df_gold.describe()}\")\n",
    "    else:\n",
    "        print(\"No CSV files found in dataset\")\n",
    "else:\n",
    "    print(\"Dataset path not found. Please check the path.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Google RSS News Integration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not load ML news classifier, only basic filtering will be used. [Errno 2] No such file or directory: 'ml_models/gold_news_classifier.pkl'\n",
      "Fetching global news (broad)...\n",
      "Error fetching news: URL can't contain control characters. '/rss/search?q=gold OR gold price OR inflation OR dollar OR interest rate OR central bank OR economy OR currency OR commodities OR market crash OR recession&hl=en&ceid=US:EN' (found at least ' ')\n",
      "No news items retrieved.\n",
      "No impactful news found (check ML model setup or broaden query).\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Load pretrained ML model and vectorizer (must be trained and exported separately)\n",
    "ML_MODEL_PATH = \"ml_models/gold_news_classifier.pkl\"\n",
    "VECTORIZER_PATH = \"ml_models/vectorizer.pkl\"\n",
    "try:\n",
    "    gold_news_classifier = joblib.load(ML_MODEL_PATH)\n",
    "    news_vectorizer = joblib.load(VECTORIZER_PATH)\n",
    "except Exception as e:\n",
    "    print(\"Warning: Could not load ML news classifier, only basic filtering will be used.\", e)\n",
    "    gold_news_classifier = None\n",
    "    news_vectorizer = None\n",
    "\n",
    "def fetch_global_news(query=\"gold OR currency OR inflation OR economy\", max_results=100, language=\"en\"):\n",
    "    \"\"\"\n",
    "    Fetch worldwide news articles from Google News RSS by using no region latch.\n",
    "    \"\"\"\n",
    "    # Remove region & country filter for global results\n",
    "    rss_url = f\"https://news.google.com/rss/search?q={query}&hl={language}&ceid=US:{language.upper()}\"\n",
    "    try:\n",
    "        feed = feedparser.parse(rss_url)\n",
    "        news_items = []\n",
    "        for entry in feed.entries[:max_results]:\n",
    "            title = entry.get('title', '')\n",
    "            summary = entry.get('summary', '')\n",
    "            published = entry.get('published', '')\n",
    "            link = entry.get('link', '')\n",
    "            news_items.append({\n",
    "                'title': title,\n",
    "                'summary': summary,\n",
    "                'published': published,\n",
    "                'link': link\n",
    "            })\n",
    "        return pd.DataFrame(news_items)\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching news: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def ml_filter_impactful_news(news_df, threshold=0.6):\n",
    "    \"\"\"\n",
    "    Use loaded ML model to filter which news are most likely to influence gold prices.\n",
    "    Assumes a binary or multi-class classifier, with probability output.\n",
    "    Returns dataframe with predicted probabilities and filter column.\n",
    "    \"\"\"\n",
    "    if gold_news_classifier is None or news_vectorizer is None or news_df.empty:\n",
    "        # Fallback: keep all news\n",
    "        news_df['ml_pred'] = 1.0  # mark all as relevant\n",
    "        news_df['ml_relevant'] = True\n",
    "        return news_df\n",
    "\n",
    "    # Use both title and summary for classification input\n",
    "    texts = (news_df['title'].fillna('') + ' ' + news_df['summary'].fillna('')).tolist()\n",
    "    X = news_vectorizer.transform(texts)\n",
    "    if hasattr(gold_news_classifier, \"predict_proba\"):\n",
    "        proba = gold_news_classifier.predict_proba(X)[:, 1]  # 2nd col = positive (relevant to gold pricing)\n",
    "    else:\n",
    "        # For classifier that doesn't support proba\n",
    "        proba = gold_news_classifier.decision_function(X)\n",
    "        proba = (proba - proba.min()) / (proba.max() - proba.min() + 1e-8)  # Scale to [0, 1]\n",
    "    news_df['ml_pred'] = proba\n",
    "    news_df['ml_relevant'] = news_df['ml_pred'] > threshold\n",
    "    return news_df\n",
    "\n",
    "def get_recent_impactful_gold_news(max_results=50):\n",
    "    \"\"\"\n",
    "    Fetch a broad set of global economic & gold/finance news, then filter using ML model.\n",
    "    Only return news predicted by the model to be recent and impactful for gold pricing.\n",
    "    \"\"\"\n",
    "    # Query includes gold and broader relevant terms for global coverage\n",
    "    global_query = (\n",
    "        \"gold OR gold price OR inflation OR dollar OR \"\n",
    "        \"interest rate OR central bank OR economy OR \"\n",
    "        \"currency OR commodities OR market crash OR recession\"\n",
    "    )\n",
    "    print(\"Fetching global news (broad)...\")\n",
    "    news_df = fetch_global_news(query=global_query, max_results=max_results * 3)\n",
    "    if news_df.empty:\n",
    "        print(\"No news items retrieved.\")\n",
    "        return news_df\n",
    "\n",
    "    # ML FILTER: Intelligent filter for news likely to affect gold prices\n",
    "    news_df_filtered = ml_filter_impactful_news(news_df)\n",
    "    impactful_df = news_df_filtered[news_df_filtered['ml_relevant']].sort_values(\"published\", ascending=False)\n",
    "    impactful_df = impactful_df.reset_index(drop=True).head(max_results)\n",
    "    print(f\"Selected {len(impactful_df)} recent, impactful news potentially influencing gold prices.\")\n",
    "    return impactful_df\n",
    "\n",
    "# Fetch, filter, and preview most impactful news\n",
    "impactful_news_df = get_recent_impactful_gold_news(max_results=30)\n",
    "if not impactful_news_df.empty:\n",
    "    print(\"\\nSample most impactful news (ML-filtered):\")\n",
    "    print(impactful_news_df[['title', 'published', 'ml_pred', 'link']].head(10))\n",
    "else:\n",
    "    print(\"No impactful news found (check ML model setup or broaden query).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Free Gold Price API Integration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gold_price_api(api_key):\n",
    "    \"\"\"\n",
    "    Fetch current gold price using Alpha Vantage API\n",
    "    \"\"\"\n",
    "    if not api_key:\n",
    "        print(\"Error: Alpha Vantage API key is required\")\n",
    "        return {\n",
    "            'current_price': None,\n",
    "            'source': 'error',\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "    \n",
    "    try:\n",
    "        url = f\"https://www.alphavantage.co/query?function=CURRENCY_EXCHANGE_RATE&from_currency=XAU&to_currency=USD&apikey={api_key}\"\n",
    "        response = requests.get(url, timeout=10)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            \n",
    "            # Check for API error messages\n",
    "            if 'Error Message' in data:\n",
    "                print(f\"API Error: {data['Error Message']}\")\n",
    "                return {\n",
    "                    'current_price': None,\n",
    "                    'source': 'api_error',\n",
    "                    'timestamp': datetime.now().isoformat()\n",
    "                }\n",
    "            \n",
    "            if 'Note' in data:\n",
    "                print(f\"API Note: {data['Note']}\")\n",
    "                return {\n",
    "                    'current_price': None,\n",
    "                    'source': 'rate_limit',\n",
    "                    'timestamp': datetime.now().isoformat()\n",
    "                }\n",
    "            \n",
    "            # Extract exchange rate\n",
    "            rate_info = data.get('Realtime Currency Exchange Rate', {})\n",
    "            if rate_info:\n",
    "                current_price = float(rate_info.get('5. Exchange Rate', 0))\n",
    "                if current_price > 0:\n",
    "                    return {\n",
    "                        'current_price': current_price,\n",
    "                        'source': 'alpha-vantage',\n",
    "                        'timestamp': datetime.now().isoformat(),\n",
    "                        'last_updated': rate_info.get('6. Last Refreshed', ''),\n",
    "                        'time_zone': rate_info.get('7. Time Zone', '')\n",
    "                    }\n",
    "        \n",
    "        print(f\"Error: Unexpected API response (Status: {response.status_code})\")\n",
    "        return {\n",
    "            'current_price': None,\n",
    "            'source': 'api_error',\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching gold price: {e}\")\n",
    "        return {\n",
    "            'current_price': None,\n",
    "            'source': 'error',\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "\n",
    "# Fetch current gold price using Alpha Vantage\n",
    "print(\"Fetching current gold price from Alpha Vantage...\")\n",
    "current_gold_data = get_gold_price_api(ALPHA_VANTAGE_API_KEY)\n",
    "\n",
    "if current_gold_data['current_price']:\n",
    "    print(f\"\\nCurrent Gold Price (USD/oz): ${current_gold_data['current_price']:.2f}\")\n",
    "    print(f\"Source: {current_gold_data['source']}\")\n",
    "    if 'last_updated' in current_gold_data:\n",
    "        print(f\"Last Updated: {current_gold_data['last_updated']}\")\n",
    "else:\n",
    "    print(\"\\nWarning: Could not fetch current gold price\")\n",
    "    print(\"Using placeholder value for model training\")\n",
    "    current_gold_data['current_price'] = 2000.0\n",
    "    current_gold_data['source'] = 'placeholder'\n",
    "\n",
    "print(f\"\\nGold Price Data: {current_gold_data}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_gold_data(df):\n",
    "    \"\"\"\n",
    "    Preprocess the gold price dataset\n",
    "    \"\"\"\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    # Convert date column to datetime (adjust column name as needed)\n",
    "    date_col = None\n",
    "    for col in df_processed.columns:\n",
    "        if 'date' in col.lower() or 'time' in col.lower():\n",
    "            date_col = col\n",
    "            break\n",
    "    \n",
    "    if date_col:\n",
    "        df_processed[date_col] = pd.to_datetime(df_processed[date_col], errors='coerce')\n",
    "        df_processed = df_processed.sort_values(date_col).reset_index(drop=True)\n",
    "    \n",
    "    # Identify price column (usually contains 'price', 'close', or 'value')\n",
    "    price_col = None\n",
    "    for col in df_processed.columns:\n",
    "        if 'price' in col.lower() or 'close' in col.lower() or 'value' in col.lower():\n",
    "            price_col = col\n",
    "            break\n",
    "    \n",
    "    # Create features\n",
    "    if price_col and df_processed[price_col].dtype in ['float64', 'int64']:\n",
    "        # Price change\n",
    "        df_processed['price_change'] = df_processed[price_col].diff()\n",
    "        df_processed['price_change_pct'] = df_processed[price_col].pct_change() * 100\n",
    "        \n",
    "        # Moving averages\n",
    "        df_processed['ma_7'] = df_processed[price_col].rolling(window=7).mean()\n",
    "        df_processed['ma_30'] = df_processed[price_col].rolling(window=30).mean()\n",
    "        \n",
    "        # Price volatility\n",
    "        df_processed['volatility'] = df_processed[price_col].rolling(window=7).std()\n",
    "        \n",
    "        # Price direction (target for classification)\n",
    "        df_processed['direction'] = (df_processed[price_col].shift(-1) > df_processed[price_col]).astype(int)\n",
    "        # Handle NaN in direction (last row will be NaN)\n",
    "        df_processed['direction'] = df_processed['direction'].fillna(0).astype(int)\n",
    "        \n",
    "        # Price range for next period (target for regression)\n",
    "        df_processed['next_price'] = df_processed[price_col].shift(-1)\n",
    "        # Create a temporary dataframe for min/max calculation\n",
    "        temp_df = pd.DataFrame({\n",
    "            'current': df_processed[price_col],\n",
    "            'next': df_processed['next_price']\n",
    "        })\n",
    "        df_processed['price_range_low'] = temp_df[['current', 'next']].min(axis=1)\n",
    "        df_processed['price_range_high'] = temp_df[['current', 'next']].max(axis=1)\n",
    "        df_processed['price_range'] = df_processed['price_range_high'] - df_processed['price_range_low']\n",
    "    \n",
    "    # Handle missing values - use forward and backward fill (modern pandas syntax)\n",
    "    df_processed = df_processed.bfill().ffill()\n",
    "    # Drop any remaining NaN rows\n",
    "    df_processed = df_processed.dropna()\n",
    "    \n",
    "    return df_processed, price_col, date_col\n",
    "\n",
    "# Preprocess the dataset\n",
    "if 'df_gold' in locals() and not df_gold.empty:\n",
    "    df_processed, price_col, date_col = preprocess_gold_data(df_gold)\n",
    "    print(f\"Processed dataset shape: {df_processed.shape}\")\n",
    "    print(f\"Price column: {price_col}\")\n",
    "    print(f\"Date column: {date_col}\")\n",
    "    print(f\"\\nProcessed data head:\")\n",
    "    print(df_processed.head())\n",
    "else:\n",
    "    print(\"Please load the dataset first in section 3\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Engineering with News and API Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_matrix(df_processed, news_sentiment=None, current_api_price=None):\n",
    "    \"\"\"\n",
    "    Create feature matrix combining historical data, news sentiment, and API price\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    \n",
    "    # Historical price features\n",
    "    if price_col and price_col in df_processed.columns:\n",
    "        feature_cols = [\n",
    "            price_col,\n",
    "            'price_change', 'price_change_pct',\n",
    "            'ma_7', 'ma_30', 'volatility'\n",
    "        ]\n",
    "        \n",
    "        # Add available features\n",
    "        available_features = [col for col in feature_cols if col in df_processed.columns]\n",
    "        X = df_processed[available_features].values\n",
    "        \n",
    "        # Add news sentiment features (if available)\n",
    "        if news_sentiment:\n",
    "            sentiment_features = [\n",
    "                news_sentiment.get('avg_sentiment', 0.0),\n",
    "                news_sentiment.get('avg_price_indicator', 0.0),\n",
    "                news_sentiment.get('avg_combined_sentiment', 0.0),\n",
    "                news_sentiment.get('positive_count', 0),\n",
    "                news_sentiment.get('negative_count', 0),\n",
    "                news_sentiment.get('rise_indicator_count', 0),\n",
    "                news_sentiment.get('fall_indicator_count', 0),\n",
    "                news_sentiment.get('news_count', 0)\n",
    "            ]\n",
    "            # Repeat sentiment for each row (or match by date if dates available)\n",
    "            sentiment_array = np.tile(sentiment_features, (len(X), 1))\n",
    "            X = np.hstack([X, sentiment_array])\n",
    "        \n",
    "        # Add current API price features (if available)\n",
    "        if current_api_price and 'current_price' in current_api_price:\n",
    "            api_price = current_api_price['current_price']\n",
    "            # Compare with last historical price\n",
    "            last_price = df_processed[price_col].iloc[-1] if len(df_processed) > 0 else api_price\n",
    "            price_diff = api_price - last_price\n",
    "            price_diff_pct = (price_diff / last_price) * 100\n",
    "            \n",
    "            api_features = np.array([[api_price, price_diff, price_diff_pct]])\n",
    "            api_features_tiled = np.tile(api_features, (len(X), 1))\n",
    "            X = np.hstack([X, api_features_tiled])\n",
    "        \n",
    "        return X, available_features\n",
    "    \n",
    "    return None, []\n",
    "\n",
    "# Create feature matrix\n",
    "if 'df_processed' in locals() and not df_processed.empty:\n",
    "    X, feature_names = create_feature_matrix(\n",
    "        df_processed,\n",
    "        news_sentiment=sentiment_stats if 'sentiment_stats' in locals() else None,\n",
    "        current_api_price=current_gold_data if 'current_gold_data' in locals() else None\n",
    "    )\n",
    "    \n",
    "    if X is not None:\n",
    "        print(f\"Feature matrix shape: {X.shape}\")\n",
    "        print(f\"Feature names: {feature_names}\")\n",
    "        print(f\"\\nFeature matrix sample:\")\n",
    "        print(X[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Training - Direction Prediction (Up/Down)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_direction_model(X, y_direction):\n",
    "    \"\"\"\n",
    "    Train a model to predict price direction (up/down)\n",
    "    \"\"\"\n",
    "    # Remove rows where target is NaN\n",
    "    valid_mask = ~np.isnan(y_direction)\n",
    "    X_clean = X[valid_mask]\n",
    "    y_clean = y_direction[valid_mask].astype(int)\n",
    "    \n",
    "    if len(X_clean) == 0:\n",
    "        print(\"No valid data for training\")\n",
    "        return None, None, None\n",
    "    \n",
    "    # Split data\n",
    "    # Check if we can stratify (need at least 2 samples per class)\n",
    "    unique_classes = np.unique(y_clean)\n",
    "    can_stratify = len(unique_classes) > 1 and all((y_clean == cls).sum() >= 2 for cls in unique_classes)\n",
    "    \n",
    "    if can_stratify:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_clean, y_clean, test_size=0.2, random_state=42, stratify=y_clean\n",
    "        )\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_clean, y_clean, test_size=0.2, random_state=42\n",
    "        )\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Train Random Forest Classifier\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Direction Prediction Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['Down', 'Up']))\n",
    "    \n",
    "    # Feature importance\n",
    "    num_features = len(model.feature_importances_)\n",
    "    feature_names_list = feature_names if 'feature_names' in globals() and len(feature_names) >= num_features else [f'feature_{i}' for i in range(num_features)]\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': feature_names_list[:num_features],\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(f\"\\nTop Features:\")\n",
    "    print(feature_importance.head(10))\n",
    "    \n",
    "    return model, scaler, feature_importance\n",
    "\n",
    "# Train direction model\n",
    "if 'X' in locals() and X is not None and 'df_processed' in locals():\n",
    "    if 'direction' in df_processed.columns:\n",
    "        y_direction = df_processed['direction'].values\n",
    "        \n",
    "        direction_model, direction_scaler, feature_importance = train_direction_model(X, y_direction)\n",
    "        \n",
    "        if direction_model is not None:\n",
    "            print(\"\\nDirection model trained successfully!\")\n",
    "    else:\n",
    "        print(\"Direction column not found. Creating it...\")\n",
    "        # Create direction column if it doesn't exist\n",
    "        if price_col in df_processed.columns:\n",
    "            df_processed['direction'] = (df_processed[price_col].shift(-1) > df_processed[price_col]).astype(int)\n",
    "            y_direction = df_processed['direction'].values\n",
    "            direction_model, direction_scaler, feature_importance = train_direction_model(X, y_direction)\n",
    "else:\n",
    "    print(\"Please complete data preprocessing first\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Training - Price Range Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_range_model(X, y_price):\n",
    "    \"\"\"\n",
    "    Train a model to predict price range (how much the price will change)\n",
    "    \"\"\"\n",
    "    # Remove rows where target is NaN\n",
    "    valid_mask = ~np.isnan(y_price)\n",
    "    X_clean = X[valid_mask]\n",
    "    y_clean = y_price[valid_mask]\n",
    "    \n",
    "    if len(X_clean) == 0:\n",
    "        print(\"No valid data for training\")\n",
    "        return None, None, None\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_clean, y_clean, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Train Random Forest Regressor for price prediction\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    print(f\"Price Range Prediction:\")\n",
    "    print(f\"Mean Absolute Error: ${mae:.2f}\")\n",
    "    print(f\"Root Mean Squared Error: ${rmse:.2f}\")\n",
    "    print(f\"Mean Actual Price: ${y_test.mean():.2f}\")\n",
    "    print(f\"Mean Predicted Price: ${y_pred.mean():.2f}\")\n",
    "    \n",
    "    return model, scaler, {'mae': mae, 'rmse': rmse}\n",
    "\n",
    "# Train range model\n",
    "if 'X' in locals() and X is not None and 'df_processed' in locals():\n",
    "    if 'next_price' in df_processed.columns:\n",
    "        y_price = df_processed['next_price'].values\n",
    "        \n",
    "        range_model, range_scaler, range_metrics = train_range_model(X, y_price)\n",
    "        \n",
    "        if range_model is not None:\n",
    "            print(\"\\nPrice range model trained successfully!\")\n",
    "    else:\n",
    "        print(\"Next price column not found. Please check data preprocessing.\")\n",
    "else:\n",
    "    print(\"Please complete data preprocessing first\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Make Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_gold_price(direction_model, direction_scaler, range_model, range_scaler, \n",
    "                       latest_features, current_price):\n",
    "    \"\"\"\n",
    "    Make predictions for gold price direction and range\n",
    "    \"\"\"\n",
    "    predictions = {}\n",
    "    \n",
    "    # Predict direction\n",
    "    if direction_model is not None and direction_scaler is not None:\n",
    "        # Use the latest features for prediction\n",
    "        latest_features_scaled = direction_scaler.transform([latest_features])\n",
    "        direction_proba = direction_model.predict_proba(latest_features_scaled)[0]\n",
    "        direction_pred = direction_model.predict(latest_features_scaled)[0]\n",
    "        \n",
    "        predictions['direction'] = 'UP' if direction_pred == 1 else 'DOWN'\n",
    "        predictions['direction_confidence'] = max(direction_proba) * 100\n",
    "        predictions['up_probability'] = direction_proba[1] * 100\n",
    "        predictions['down_probability'] = direction_proba[0] * 100\n",
    "    \n",
    "    # Predict price range\n",
    "    if range_model is not None and range_scaler is not None:\n",
    "        latest_features_scaled = range_scaler.transform([latest_features])\n",
    "        predicted_price = range_model.predict(latest_features_scaled)[0]\n",
    "        \n",
    "        # Calculate range\n",
    "        price_change = predicted_price - current_price\n",
    "        price_change_pct = (price_change / current_price) * 100\n",
    "        \n",
    "        # Estimate uncertainty (using model's feature importance as proxy)\n",
    "        # In production, use prediction intervals or quantile regression\n",
    "        uncertainty = abs(price_change) * 0.1  # 10% uncertainty estimate\n",
    "        \n",
    "        predictions['predicted_price'] = predicted_price\n",
    "        predictions['current_price'] = current_price\n",
    "        predictions['expected_change'] = price_change\n",
    "        predictions['expected_change_pct'] = price_change_pct\n",
    "        predictions['price_range_low'] = predicted_price - uncertainty\n",
    "        predictions['price_range_high'] = predicted_price + uncertainty\n",
    "        predictions['range_span'] = uncertainty * 2\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Make predictions\n",
    "if 'direction_model' in locals() and direction_model is not None:\n",
    "    if 'X' in locals() and X is not None and len(X) > 0:\n",
    "        latest_features = X[-1]  # Use most recent data point\n",
    "        current_price_val = current_gold_data.get('current_price', df_processed[price_col].iloc[-1] if 'df_processed' in locals() and price_col in df_processed.columns else 2000.0)\n",
    "        \n",
    "        predictions = predict_gold_price(\n",
    "            direction_model, direction_scaler,\n",
    "            range_model if 'range_model' in locals() else None,\n",
    "            range_scaler if 'range_scaler' in locals() else None,\n",
    "            latest_features,\n",
    "            current_price_val\n",
    "        )\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"GOLD PRICE PREDICTION RESULTS\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        if 'direction' in predictions:\n",
    "            print(f\"\\nDirection Prediction: {predictions['direction']}\")\n",
    "            print(f\"Confidence: {predictions['direction_confidence']:.2f}%\")\n",
    "            print(f\"  - Up Probability: {predictions['up_probability']:.2f}%\")\n",
    "            print(f\"  - Down Probability: {predictions['down_probability']:.2f}%\")\n",
    "        \n",
    "        if 'predicted_price' in predictions:\n",
    "            print(f\"\\nPrice Prediction:\")\n",
    "            print(f\"  Current Price: ${predictions['current_price']:.2f}/oz\")\n",
    "            print(f\"  Predicted Price: ${predictions['predicted_price']:.2f}/oz\")\n",
    "            print(f\"  Expected Change: ${predictions['expected_change']:.2f} ({predictions['expected_change_pct']:+.2f}%)\")\n",
    "            print(f\"\\nPredicted Price Range:\")\n",
    "            print(f\"  Low: ${predictions['price_range_low']:.2f}/oz\")\n",
    "            print(f\"  High: ${predictions['price_range_high']:.2f}/oz\")\n",
    "            print(f\"  Range Span: ${predictions['range_span']:.2f}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "    else:\n",
    "        print(\"No features available for prediction\")\n",
    "else:\n",
    "    print(\"Please train the models first\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize gold price trends\n",
    "if 'df_processed' in locals() and price_col and date_col:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Plot 1: Price over time\n",
    "    axes[0, 0].plot(df_processed[date_col], df_processed[price_col], linewidth=2)\n",
    "    axes[0, 0].set_title('Gold Price Over Time', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Date')\n",
    "    axes[0, 0].set_ylabel('Price (USD/oz)')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add prediction point if available\n",
    "    if 'predictions' in locals() and 'predicted_price' in predictions:\n",
    "        last_date = df_processed[date_col].iloc[-1]\n",
    "        next_date = last_date + pd.Timedelta(days=1)\n",
    "        axes[0, 0].plot(next_date, predictions['predicted_price'], 'ro', markersize=10, label='Prediction')\n",
    "        axes[0, 0].errorbar(next_date, predictions['predicted_price'], \n",
    "                           yerr=[[predictions['predicted_price'] - predictions['price_range_low']],\n",
    "                                 [predictions['price_range_high'] - predictions['predicted_price']]],\n",
    "                           fmt='ro', capsize=5, label='Prediction Range')\n",
    "        axes[0, 0].legend()\n",
    "    \n",
    "    # Plot 2: Price changes\n",
    "    if 'price_change_pct' in df_processed.columns:\n",
    "        axes[0, 1].plot(df_processed[date_col], df_processed['price_change_pct'], alpha=0.7)\n",
    "        axes[0, 1].axhline(y=0, color='r', linestyle='--', alpha=0.5)\n",
    "        axes[0, 1].set_title('Price Change Percentage', fontsize=14, fontweight='bold')\n",
    "        axes[0, 1].set_xlabel('Date')\n",
    "        axes[0, 1].set_ylabel('Change (%)')\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Moving averages\n",
    "    if 'ma_7' in df_processed.columns and 'ma_30' in df_processed.columns:\n",
    "        axes[1, 0].plot(df_processed[date_col], df_processed[price_col], label='Price', alpha=0.7)\n",
    "        axes[1, 0].plot(df_processed[date_col], df_processed['ma_7'], label='MA 7', linewidth=2)\n",
    "        axes[1, 0].plot(df_processed[date_col], df_processed['ma_30'], label='MA 30', linewidth=2)\n",
    "        axes[1, 0].set_title('Price with Moving Averages', fontsize=14, fontweight='bold')\n",
    "        axes[1, 0].set_xlabel('Date')\n",
    "        axes[1, 0].set_ylabel('Price (USD/oz)')\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: News sentiment and price indicators\n",
    "    if 'news_df' in locals() and not news_df.empty and 'sentiment_stats' in locals():\n",
    "        # Create combined sentiment visualization\n",
    "        rise_fall_counts = [\n",
    "            sentiment_stats.get('rise_indicator_count', 0),\n",
    "            sentiment_stats.get('fall_indicator_count', 0)\n",
    "        ]\n",
    "        labels = ['Rise Indicators', 'Fall Indicators']\n",
    "        colors = ['green', 'red']\n",
    "        axes[1, 1].bar(labels, rise_fall_counts, color=colors, alpha=0.7)\n",
    "        axes[1, 1].set_title('News Price Direction Indicators', fontsize=14, fontweight='bold')\n",
    "        axes[1, 1].set_ylabel('Number of News Items')\n",
    "        axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Add combined sentiment score as text\n",
    "        combined_sent = sentiment_stats.get('avg_combined_sentiment', 0.0)\n",
    "        if combined_sent > 0.1:\n",
    "            signal_text = 'RISE Signal'\n",
    "            signal_color = 'green'\n",
    "        elif combined_sent < -0.1:\n",
    "            signal_text = 'FALL Signal'\n",
    "            signal_color = 'red'\n",
    "        else:\n",
    "            signal_text = 'NEUTRAL'\n",
    "            signal_color = 'gray'\n",
    "        \n",
    "        max_count = max(rise_fall_counts) if rise_fall_counts and max(rise_fall_counts) > 0 else 1\n",
    "        axes[1, 1].text(0.5, max_count * 0.9, f'Signal: {signal_text}', \n",
    "                       ha='center', fontsize=12, fontweight='bold', color=signal_color,\n",
    "                       transform=axes[1, 1].transData)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Data not available for visualization\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Notes and Next Steps\n",
    "\n",
    "### API Configuration:\n",
    "- **Alpha Vantage**: Used for real-time gold price data (API key configured in Configuration section)\n",
    "- **Google RSS**: Used for news sentiment analysis with gold-specific price indicators\n",
    "\n",
    "### Model Improvements:\n",
    "- Use more sophisticated models (LSTM, XGBoost, etc.)\n",
    "- Implement prediction intervals for better uncertainty estimation\n",
    "- Add more features (economic indicators, other commodity prices)\n",
    "- Implement time-series cross-validation\n",
    "- Add ensemble methods\n",
    "- Enhance keyword detection for news analysis\n",
    "\n",
    "### Data Updates:\n",
    "- Set up scheduled runs to fetch latest news and API prices\n",
    "- Implement real-time monitoring\n",
    "- Create alerts for significant price movements\n",
    "- Expand keyword vocabulary for better price direction prediction\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
