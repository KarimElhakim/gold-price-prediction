{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gold Price Prediction with News Integration\n",
    "\n",
    "This notebook predicts gold price direction (up/down) and price range using:\n",
    "- Historical gold price data from Kaggle\n",
    "- Google RSS news feeds for latest news sentiment\n",
    "- Real-time gold price API for current prices\n",
    "\n",
    "## Prediction Goals\n",
    "1. Predict whether gold price will go UP or DOWN\n",
    "2. Predict the price range/amount of change\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Configuration\n",
    "\n",
    "Set your Kaggle API token here (or use environment variables in Colab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "KAGGLE_API_TOKEN = \"KGAT_b352cb91c46b038224e3d90adb8d8c32\"\n",
    "ALPHA_VANTAGE_API_KEY = \"EF6488BOEZN0B69R\"\n",
    "\n",
    "# Set environment variable for Kaggle\n",
    "import os\n",
    "os.environ['KAGGLE_API_TOKEN'] = KAGGLE_API_TOKEN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Setup and Installation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install required packages\n",
    "!pip install kagglehub pandas numpy scikit-learn matplotlib seaborn feedparser requests beautifulsoup4 textblob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Kaggle dataset using kagglehub\n",
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"sid321axn/gold-price-prediction-dataset\")\n",
    "print(\"Path to dataset files:\", path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For RSS feeds and news\n",
    "import feedparser\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from textblob import TextBlob\n",
    "\n",
    "# For API calls\n",
    "import json\n",
    "import time\n",
    "\n",
    "# For machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, classification_report, mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Explore Kaggle Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "# Adjust the path based on your downloaded dataset structure\n",
    "dataset_path = path\n",
    "print(f\"Dataset located at: {dataset_path}\")\n",
    "\n",
    "# List files in the dataset\n",
    "if os.path.exists(dataset_path):\n",
    "    files = os.listdir(dataset_path)\n",
    "    print(\"Files in dataset:\", files)\n",
    "    \n",
    "    # Load the main CSV file (adjust filename as needed)\n",
    "    csv_files = [f for f in files if f.endswith('.csv')]\n",
    "    if csv_files:\n",
    "        df_gold = pd.read_csv(os.path.join(dataset_path, csv_files[0]))\n",
    "        print(f\"\\nLoaded: {csv_files[0]}\")\n",
    "        print(f\"Shape: {df_gold.shape}\")\n",
    "        print(f\"\\nFirst few rows:\")\n",
    "        print(df_gold.head())\n",
    "        print(f\"\\nColumn names: {df_gold.columns.tolist()}\")\n",
    "        print(f\"\\nData types:\\n{df_gold.dtypes}\")\n",
    "        print(f\"\\nBasic statistics:\\n{df_gold.describe()}\")\n",
    "    else:\n",
    "        print(\"No CSV files found in dataset\")\n",
    "else:\n",
    "    print(\"Dataset path not found. Please check the path.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Google RSS News Integration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_gold_price_indicators(text):\n",
    "    \"\"\"\n",
    "    Analyze text for keywords that indicate gold price rise or fall\n",
    "    Returns: -1 (fall), 0 (neutral), 1 (rise)\n",
    "    \"\"\"\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Keywords indicating price rise\n",
    "    rise_keywords = [\n",
    "        'rise', 'surge', 'spike', 'rally', 'gain', 'jump', 'climb', 'increase',\n",
    "        'soar', 'peak', 'high', 'bullish', 'strong', 'upward', 'momentum',\n",
    "        'demand', 'safe haven', 'inflation hedge', 'uncertainty', 'crisis',\n",
    "        'geopolitical', 'dollar weak', 'interest rate cut', 'quantitative easing'\n",
    "    ]\n",
    "    \n",
    "    # Keywords indicating price fall\n",
    "    fall_keywords = [\n",
    "        'fall', 'drop', 'decline', 'plunge', 'crash', 'slide', 'tumble', 'dip',\n",
    "        'retreat', 'low', 'bearish', 'weak', 'downward', 'lose', 'sell-off',\n",
    "        'dollar strong', 'interest rate hike', 'strengthening economy',\n",
    "        'risk-on', 'stock market rally', 'safe haven demand fades'\n",
    "    ]\n",
    "    \n",
    "    rise_count = sum(1 for keyword in rise_keywords if keyword in text_lower)\n",
    "    fall_count = sum(1 for keyword in fall_keywords if keyword in text_lower)\n",
    "    \n",
    "    if rise_count > fall_count:\n",
    "        return 1  # Indicates price rise\n",
    "    elif fall_count > rise_count:\n",
    "        return -1  # Indicates price fall\n",
    "    else:\n",
    "        return 0  # Neutral\n",
    "\n",
    "def get_news_sentiment(query=\"gold price\", max_results=30):\n",
    "    \"\"\"\n",
    "    Fetch news from Google RSS feeds and analyze sentiment with gold-specific indicators\n",
    "    \"\"\"\n",
    "    rss_url = f\"https://news.google.com/rss/search?q={query}&hl=en-US&gl=US&ceid=US:en\"\n",
    "    \n",
    "    try:\n",
    "        feed = feedparser.parse(rss_url)\n",
    "        news_items = []\n",
    "        \n",
    "        for entry in feed.entries[:max_results]:\n",
    "            title = entry.get('title', '')\n",
    "            summary = entry.get('summary', '')\n",
    "            published = entry.get('published', '')\n",
    "            link = entry.get('link', '')\n",
    "            \n",
    "            # Combine title and summary for analysis\n",
    "            text = f\"{title} {summary}\"\n",
    "            \n",
    "            # General sentiment analysis\n",
    "            blob = TextBlob(text)\n",
    "            sentiment_score = blob.sentiment.polarity  # Range: -1 to 1\n",
    "            \n",
    "            # Gold-specific price direction indicator\n",
    "            price_indicator = analyze_gold_price_indicators(text)\n",
    "            \n",
    "            # Combine general sentiment with price-specific indicator\n",
    "            # Weight price indicator more heavily for gold predictions\n",
    "            combined_sentiment = (sentiment_score * 0.3) + (price_indicator * 0.7)\n",
    "            \n",
    "            news_items.append({\n",
    "                'title': title,\n",
    "                'summary': summary,\n",
    "                'published': published,\n",
    "                'link': link,\n",
    "                'sentiment': sentiment_score,\n",
    "                'price_indicator': price_indicator,\n",
    "                'combined_sentiment': combined_sentiment\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(news_items)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching news: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def aggregate_news_sentiment(news_df):\n",
    "    \"\"\"\n",
    "    Aggregate news sentiment with gold price direction indicators\n",
    "    \"\"\"\n",
    "    if news_df.empty:\n",
    "        return {\n",
    "            'avg_sentiment': 0.0,\n",
    "            'avg_price_indicator': 0.0,\n",
    "            'avg_combined_sentiment': 0.0,\n",
    "            'positive_count': 0,\n",
    "            'negative_count': 0,\n",
    "            'rise_indicator_count': 0,\n",
    "            'fall_indicator_count': 0,\n",
    "            'news_count': 0\n",
    "        }\n",
    "    \n",
    "    avg_sentiment = news_df['sentiment'].mean()\n",
    "    avg_price_indicator = news_df['price_indicator'].mean()\n",
    "    avg_combined_sentiment = news_df['combined_sentiment'].mean()\n",
    "    \n",
    "    positive_count = (news_df['sentiment'] > 0.1).sum()\n",
    "    negative_count = (news_df['sentiment'] < -0.1).sum()\n",
    "    rise_indicator_count = (news_df['price_indicator'] > 0).sum()\n",
    "    fall_indicator_count = (news_df['price_indicator'] < 0).sum()\n",
    "    \n",
    "    return {\n",
    "        'avg_sentiment': avg_sentiment,\n",
    "        'avg_price_indicator': avg_price_indicator,\n",
    "        'avg_combined_sentiment': avg_combined_sentiment,\n",
    "        'positive_count': positive_count,\n",
    "        'negative_count': negative_count,\n",
    "        'rise_indicator_count': rise_indicator_count,\n",
    "        'fall_indicator_count': fall_indicator_count,\n",
    "        'news_count': len(news_df)\n",
    "    }\n",
    "\n",
    "# Fetch current gold-related news\n",
    "print(\"Fetching latest gold price news...\")\n",
    "news_df = get_news_sentiment(\"gold price OR gold market OR gold trading OR gold futures\", max_results=30)\n",
    "print(f\"\\nFetched {len(news_df)} news items\")\n",
    "\n",
    "if not news_df.empty:\n",
    "    print(\"\\nSample news items with price indicators:\")\n",
    "    display_cols = ['title', 'sentiment', 'price_indicator', 'combined_sentiment']\n",
    "    print(news_df[display_cols].head(10))\n",
    "    \n",
    "    # Aggregate sentiment\n",
    "    sentiment_stats = aggregate_news_sentiment(news_df)\n",
    "    print(f\"\\nNews Sentiment Statistics:\")\n",
    "    print(f\"Average General Sentiment: {sentiment_stats['avg_sentiment']:.3f}\")\n",
    "    print(f\"Average Price Indicator: {sentiment_stats['avg_price_indicator']:.3f} (1=rise, -1=fall)\")\n",
    "    print(f\"Average Combined Sentiment: {sentiment_stats['avg_combined_sentiment']:.3f}\")\n",
    "    print(f\"\\nPrice Direction Indicators:\")\n",
    "    print(f\"  News suggesting RISE: {sentiment_stats['rise_indicator_count']}\")\n",
    "    print(f\"  News suggesting FALL: {sentiment_stats['fall_indicator_count']}\")\n",
    "    print(f\"\\nGeneral Sentiment:\")\n",
    "    print(f\"  Positive News: {sentiment_stats['positive_count']}\")\n",
    "    print(f\"  Negative News: {sentiment_stats['negative_count']}\")\n",
    "    print(f\"  Total News: {sentiment_stats['news_count']}\")\n",
    "    \n",
    "    # Price direction prediction from news\n",
    "    if sentiment_stats['avg_combined_sentiment'] > 0.1:\n",
    "        print(f\"\\nNews Analysis: INDICATES GOLD PRICE RISE\")\n",
    "    elif sentiment_stats['avg_combined_sentiment'] < -0.1:\n",
    "        print(f\"\\nNews Analysis: INDICATES GOLD PRICE FALL\")\n",
    "    else:\n",
    "        print(f\"\\nNews Analysis: NEUTRAL/MIXED SIGNALS\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Free Gold Price API Integration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gold_price_api(api_key):\n",
    "    \"\"\"\n",
    "    Fetch current gold price using Alpha Vantage API\n",
    "    \"\"\"\n",
    "    if not api_key:\n",
    "        print(\"Error: Alpha Vantage API key is required\")\n",
    "        return {\n",
    "            'current_price': None,\n",
    "            'source': 'error',\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "    \n",
    "    try:\n",
    "        url = f\"https://www.alphavantage.co/query?function=CURRENCY_EXCHANGE_RATE&from_currency=XAU&to_currency=USD&apikey={api_key}\"\n",
    "        response = requests.get(url, timeout=10)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            \n",
    "            # Check for API error messages\n",
    "            if 'Error Message' in data:\n",
    "                print(f\"API Error: {data['Error Message']}\")\n",
    "                return {\n",
    "                    'current_price': None,\n",
    "                    'source': 'api_error',\n",
    "                    'timestamp': datetime.now().isoformat()\n",
    "                }\n",
    "            \n",
    "            if 'Note' in data:\n",
    "                print(f\"API Note: {data['Note']}\")\n",
    "                return {\n",
    "                    'current_price': None,\n",
    "                    'source': 'rate_limit',\n",
    "                    'timestamp': datetime.now().isoformat()\n",
    "                }\n",
    "            \n",
    "            # Extract exchange rate\n",
    "            rate_info = data.get('Realtime Currency Exchange Rate', {})\n",
    "            if rate_info:\n",
    "                current_price = float(rate_info.get('5. Exchange Rate', 0))\n",
    "                if current_price > 0:\n",
    "                    return {\n",
    "                        'current_price': current_price,\n",
    "                        'source': 'alpha-vantage',\n",
    "                        'timestamp': datetime.now().isoformat(),\n",
    "                        'last_updated': rate_info.get('6. Last Refreshed', ''),\n",
    "                        'time_zone': rate_info.get('7. Time Zone', '')\n",
    "                    }\n",
    "        \n",
    "        print(f\"Error: Unexpected API response (Status: {response.status_code})\")\n",
    "        return {\n",
    "            'current_price': None,\n",
    "            'source': 'api_error',\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching gold price: {e}\")\n",
    "        return {\n",
    "            'current_price': None,\n",
    "            'source': 'error',\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "\n",
    "# Fetch current gold price using Alpha Vantage\n",
    "print(\"Fetching current gold price from Alpha Vantage...\")\n",
    "current_gold_data = get_gold_price_api(ALPHA_VANTAGE_API_KEY)\n",
    "\n",
    "if current_gold_data['current_price']:\n",
    "    print(f\"\\nCurrent Gold Price (USD/oz): ${current_gold_data['current_price']:.2f}\")\n",
    "    print(f\"Source: {current_gold_data['source']}\")\n",
    "    if 'last_updated' in current_gold_data:\n",
    "        print(f\"Last Updated: {current_gold_data['last_updated']}\")\n",
    "else:\n",
    "    print(\"\\nWarning: Could not fetch current gold price\")\n",
    "    print(\"Using placeholder value for model training\")\n",
    "    current_gold_data['current_price'] = 2000.0\n",
    "    current_gold_data['source'] = 'placeholder'\n",
    "\n",
    "print(f\"\\nGold Price Data: {current_gold_data}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_gold_data(df):\n",
    "    \"\"\"\n",
    "    Preprocess the gold price dataset\n",
    "    \"\"\"\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    # Convert date column to datetime (adjust column name as needed)\n",
    "    date_col = None\n",
    "    for col in df_processed.columns:\n",
    "        if 'date' in col.lower() or 'time' in col.lower():\n",
    "            date_col = col\n",
    "            break\n",
    "    \n",
    "    if date_col:\n",
    "        df_processed[date_col] = pd.to_datetime(df_processed[date_col], errors='coerce')\n",
    "        df_processed = df_processed.sort_values(date_col).reset_index(drop=True)\n",
    "    \n",
    "    # Identify price column (usually contains 'price', 'close', or 'value')\n",
    "    price_col = None\n",
    "    for col in df_processed.columns:\n",
    "        if 'price' in col.lower() or 'close' in col.lower() or 'value' in col.lower():\n",
    "            price_col = col\n",
    "            break\n",
    "    \n",
    "    # Create features\n",
    "    if price_col and df_processed[price_col].dtype in ['float64', 'int64']:\n",
    "        # Price change\n",
    "        df_processed['price_change'] = df_processed[price_col].diff()\n",
    "        df_processed['price_change_pct'] = df_processed[price_col].pct_change() * 100\n",
    "        \n",
    "        # Moving averages\n",
    "        df_processed['ma_7'] = df_processed[price_col].rolling(window=7).mean()\n",
    "        df_processed['ma_30'] = df_processed[price_col].rolling(window=30).mean()\n",
    "        \n",
    "        # Price volatility\n",
    "        df_processed['volatility'] = df_processed[price_col].rolling(window=7).std()\n",
    "        \n",
    "        # Price direction (target for classification)\n",
    "        df_processed['direction'] = (df_processed[price_col].shift(-1) > df_processed[price_col]).astype(int)\n",
    "        # Handle NaN in direction (last row will be NaN)\n",
    "        df_processed['direction'] = df_processed['direction'].fillna(0).astype(int)\n",
    "        \n",
    "        # Price range for next period (target for regression)\n",
    "        df_processed['next_price'] = df_processed[price_col].shift(-1)\n",
    "        # Create a temporary dataframe for min/max calculation\n",
    "        temp_df = pd.DataFrame({\n",
    "            'current': df_processed[price_col],\n",
    "            'next': df_processed['next_price']\n",
    "        })\n",
    "        df_processed['price_range_low'] = temp_df[['current', 'next']].min(axis=1)\n",
    "        df_processed['price_range_high'] = temp_df[['current', 'next']].max(axis=1)\n",
    "        df_processed['price_range'] = df_processed['price_range_high'] - df_processed['price_range_low']\n",
    "    \n",
    "    # Handle missing values - use forward and backward fill (modern pandas syntax)\n",
    "    df_processed = df_processed.bfill().ffill()\n",
    "    # Drop any remaining NaN rows\n",
    "    df_processed = df_processed.dropna()\n",
    "    \n",
    "    return df_processed, price_col, date_col\n",
    "\n",
    "# Preprocess the dataset\n",
    "if 'df_gold' in locals() and not df_gold.empty:\n",
    "    df_processed, price_col, date_col = preprocess_gold_data(df_gold)\n",
    "    print(f\"Processed dataset shape: {df_processed.shape}\")\n",
    "    print(f\"Price column: {price_col}\")\n",
    "    print(f\"Date column: {date_col}\")\n",
    "    print(f\"\\nProcessed data head:\")\n",
    "    print(df_processed.head())\n",
    "else:\n",
    "    print(\"Please load the dataset first in section 3\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Engineering with News and API Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_matrix(df_processed, news_sentiment=None, current_api_price=None):\n",
    "    \"\"\"\n",
    "    Create feature matrix combining historical data, news sentiment, and API price\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    \n",
    "    # Historical price features\n",
    "    if price_col and price_col in df_processed.columns:\n",
    "        feature_cols = [\n",
    "            price_col,\n",
    "            'price_change', 'price_change_pct',\n",
    "            'ma_7', 'ma_30', 'volatility'\n",
    "        ]\n",
    "        \n",
    "        # Add available features\n",
    "        available_features = [col for col in feature_cols if col in df_processed.columns]\n",
    "        X = df_processed[available_features].values\n",
    "        \n",
    "        # Add news sentiment features (if available)\n",
    "        if news_sentiment:\n",
    "            sentiment_features = [\n",
    "                news_sentiment.get('avg_sentiment', 0.0),\n",
    "                news_sentiment.get('avg_price_indicator', 0.0),\n",
    "                news_sentiment.get('avg_combined_sentiment', 0.0),\n",
    "                news_sentiment.get('positive_count', 0),\n",
    "                news_sentiment.get('negative_count', 0),\n",
    "                news_sentiment.get('rise_indicator_count', 0),\n",
    "                news_sentiment.get('fall_indicator_count', 0),\n",
    "                news_sentiment.get('news_count', 0)\n",
    "            ]\n",
    "            # Repeat sentiment for each row (or match by date if dates available)\n",
    "            sentiment_array = np.tile(sentiment_features, (len(X), 1))\n",
    "            X = np.hstack([X, sentiment_array])\n",
    "        \n",
    "        # Add current API price features (if available)\n",
    "        if current_api_price and 'current_price' in current_api_price:\n",
    "            api_price = current_api_price['current_price']\n",
    "            # Compare with last historical price\n",
    "            last_price = df_processed[price_col].iloc[-1] if len(df_processed) > 0 else api_price\n",
    "            price_diff = api_price - last_price\n",
    "            price_diff_pct = (price_diff / last_price) * 100\n",
    "            \n",
    "            api_features = np.array([[api_price, price_diff, price_diff_pct]])\n",
    "            api_features_tiled = np.tile(api_features, (len(X), 1))\n",
    "            X = np.hstack([X, api_features_tiled])\n",
    "        \n",
    "        return X, available_features\n",
    "    \n",
    "    return None, []\n",
    "\n",
    "# Create feature matrix\n",
    "if 'df_processed' in locals() and not df_processed.empty:\n",
    "    X, feature_names = create_feature_matrix(\n",
    "        df_processed,\n",
    "        news_sentiment=sentiment_stats if 'sentiment_stats' in locals() else None,\n",
    "        current_api_price=current_gold_data if 'current_gold_data' in locals() else None\n",
    "    )\n",
    "    \n",
    "    if X is not None:\n",
    "        print(f\"Feature matrix shape: {X.shape}\")\n",
    "        print(f\"Feature names: {feature_names}\")\n",
    "        print(f\"\\nFeature matrix sample:\")\n",
    "        print(X[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Training - Direction Prediction (Up/Down)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_direction_model(X, y_direction):\n",
    "    \"\"\"\n",
    "    Train a model to predict price direction (up/down)\n",
    "    \"\"\"\n",
    "    # Remove rows where target is NaN\n",
    "    valid_mask = ~np.isnan(y_direction)\n",
    "    X_clean = X[valid_mask]\n",
    "    y_clean = y_direction[valid_mask].astype(int)\n",
    "    \n",
    "    if len(X_clean) == 0:\n",
    "        print(\"No valid data for training\")\n",
    "        return None, None, None\n",
    "    \n",
    "    # Split data\n",
    "    # Check if we can stratify (need at least 2 samples per class)\n",
    "    unique_classes = np.unique(y_clean)\n",
    "    can_stratify = len(unique_classes) > 1 and all((y_clean == cls).sum() >= 2 for cls in unique_classes)\n",
    "    \n",
    "    if can_stratify:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_clean, y_clean, test_size=0.2, random_state=42, stratify=y_clean\n",
    "        )\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_clean, y_clean, test_size=0.2, random_state=42\n",
    "        )\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Train Random Forest Classifier\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Direction Prediction Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['Down', 'Up']))\n",
    "    \n",
    "    # Feature importance\n",
    "    num_features = len(model.feature_importances_)\n",
    "    feature_names_list = feature_names if 'feature_names' in globals() and len(feature_names) >= num_features else [f'feature_{i}' for i in range(num_features)]\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': feature_names_list[:num_features],\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(f\"\\nTop Features:\")\n",
    "    print(feature_importance.head(10))\n",
    "    \n",
    "    return model, scaler, feature_importance\n",
    "\n",
    "# Train direction model\n",
    "if 'X' in locals() and X is not None and 'df_processed' in locals():\n",
    "    if 'direction' in df_processed.columns:\n",
    "        y_direction = df_processed['direction'].values\n",
    "        \n",
    "        direction_model, direction_scaler, feature_importance = train_direction_model(X, y_direction)\n",
    "        \n",
    "        if direction_model is not None:\n",
    "            print(\"\\nDirection model trained successfully!\")\n",
    "    else:\n",
    "        print(\"Direction column not found. Creating it...\")\n",
    "        # Create direction column if it doesn't exist\n",
    "        if price_col in df_processed.columns:\n",
    "            df_processed['direction'] = (df_processed[price_col].shift(-1) > df_processed[price_col]).astype(int)\n",
    "            y_direction = df_processed['direction'].values\n",
    "            direction_model, direction_scaler, feature_importance = train_direction_model(X, y_direction)\n",
    "else:\n",
    "    print(\"Please complete data preprocessing first\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Training - Price Range Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_range_model(X, y_price):\n",
    "    \"\"\"\n",
    "    Train a model to predict price range (how much the price will change)\n",
    "    \"\"\"\n",
    "    # Remove rows where target is NaN\n",
    "    valid_mask = ~np.isnan(y_price)\n",
    "    X_clean = X[valid_mask]\n",
    "    y_clean = y_price[valid_mask]\n",
    "    \n",
    "    if len(X_clean) == 0:\n",
    "        print(\"No valid data for training\")\n",
    "        return None, None, None\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_clean, y_clean, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Train Random Forest Regressor for price prediction\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    print(f\"Price Range Prediction:\")\n",
    "    print(f\"Mean Absolute Error: ${mae:.2f}\")\n",
    "    print(f\"Root Mean Squared Error: ${rmse:.2f}\")\n",
    "    print(f\"Mean Actual Price: ${y_test.mean():.2f}\")\n",
    "    print(f\"Mean Predicted Price: ${y_pred.mean():.2f}\")\n",
    "    \n",
    "    return model, scaler, {'mae': mae, 'rmse': rmse}\n",
    "\n",
    "# Train range model\n",
    "if 'X' in locals() and X is not None and 'df_processed' in locals():\n",
    "    if 'next_price' in df_processed.columns:\n",
    "        y_price = df_processed['next_price'].values\n",
    "        \n",
    "        range_model, range_scaler, range_metrics = train_range_model(X, y_price)\n",
    "        \n",
    "        if range_model is not None:\n",
    "            print(\"\\nPrice range model trained successfully!\")\n",
    "    else:\n",
    "        print(\"Next price column not found. Please check data preprocessing.\")\n",
    "else:\n",
    "    print(\"Please complete data preprocessing first\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Make Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_gold_price(direction_model, direction_scaler, range_model, range_scaler, \n",
    "                       latest_features, current_price):\n",
    "    \"\"\"\n",
    "    Make predictions for gold price direction and range\n",
    "    \"\"\"\n",
    "    predictions = {}\n",
    "    \n",
    "    # Predict direction\n",
    "    if direction_model is not None and direction_scaler is not None:\n",
    "        # Use the latest features for prediction\n",
    "        latest_features_scaled = direction_scaler.transform([latest_features])\n",
    "        direction_proba = direction_model.predict_proba(latest_features_scaled)[0]\n",
    "        direction_pred = direction_model.predict(latest_features_scaled)[0]\n",
    "        \n",
    "        predictions['direction'] = 'UP' if direction_pred == 1 else 'DOWN'\n",
    "        predictions['direction_confidence'] = max(direction_proba) * 100\n",
    "        predictions['up_probability'] = direction_proba[1] * 100\n",
    "        predictions['down_probability'] = direction_proba[0] * 100\n",
    "    \n",
    "    # Predict price range\n",
    "    if range_model is not None and range_scaler is not None:\n",
    "        latest_features_scaled = range_scaler.transform([latest_features])\n",
    "        predicted_price = range_model.predict(latest_features_scaled)[0]\n",
    "        \n",
    "        # Calculate range\n",
    "        price_change = predicted_price - current_price\n",
    "        price_change_pct = (price_change / current_price) * 100\n",
    "        \n",
    "        # Estimate uncertainty (using model's feature importance as proxy)\n",
    "        # In production, use prediction intervals or quantile regression\n",
    "        uncertainty = abs(price_change) * 0.1  # 10% uncertainty estimate\n",
    "        \n",
    "        predictions['predicted_price'] = predicted_price\n",
    "        predictions['current_price'] = current_price\n",
    "        predictions['expected_change'] = price_change\n",
    "        predictions['expected_change_pct'] = price_change_pct\n",
    "        predictions['price_range_low'] = predicted_price - uncertainty\n",
    "        predictions['price_range_high'] = predicted_price + uncertainty\n",
    "        predictions['range_span'] = uncertainty * 2\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Make predictions\n",
    "if 'direction_model' in locals() and direction_model is not None:\n",
    "    if 'X' in locals() and X is not None and len(X) > 0:\n",
    "        latest_features = X[-1]  # Use most recent data point\n",
    "        current_price_val = current_gold_data.get('current_price', df_processed[price_col].iloc[-1] if 'df_processed' in locals() and price_col in df_processed.columns else 2000.0)\n",
    "        \n",
    "        predictions = predict_gold_price(\n",
    "            direction_model, direction_scaler,\n",
    "            range_model if 'range_model' in locals() else None,\n",
    "            range_scaler if 'range_scaler' in locals() else None,\n",
    "            latest_features,\n",
    "            current_price_val\n",
    "        )\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"GOLD PRICE PREDICTION RESULTS\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        if 'direction' in predictions:\n",
    "            print(f\"\\nDirection Prediction: {predictions['direction']}\")\n",
    "            print(f\"Confidence: {predictions['direction_confidence']:.2f}%\")\n",
    "            print(f\"  - Up Probability: {predictions['up_probability']:.2f}%\")\n",
    "            print(f\"  - Down Probability: {predictions['down_probability']:.2f}%\")\n",
    "        \n",
    "        if 'predicted_price' in predictions:\n",
    "            print(f\"\\nPrice Prediction:\")\n",
    "            print(f\"  Current Price: ${predictions['current_price']:.2f}/oz\")\n",
    "            print(f\"  Predicted Price: ${predictions['predicted_price']:.2f}/oz\")\n",
    "            print(f\"  Expected Change: ${predictions['expected_change']:.2f} ({predictions['expected_change_pct']:+.2f}%)\")\n",
    "            print(f\"\\nPredicted Price Range:\")\n",
    "            print(f\"  Low: ${predictions['price_range_low']:.2f}/oz\")\n",
    "            print(f\"  High: ${predictions['price_range_high']:.2f}/oz\")\n",
    "            print(f\"  Range Span: ${predictions['range_span']:.2f}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "    else:\n",
    "        print(\"No features available for prediction\")\n",
    "else:\n",
    "    print(\"Please train the models first\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize gold price trends\n",
    "if 'df_processed' in locals() and price_col and date_col:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Plot 1: Price over time\n",
    "    axes[0, 0].plot(df_processed[date_col], df_processed[price_col], linewidth=2)\n",
    "    axes[0, 0].set_title('Gold Price Over Time', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Date')\n",
    "    axes[0, 0].set_ylabel('Price (USD/oz)')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add prediction point if available\n",
    "    if 'predictions' in locals() and 'predicted_price' in predictions:\n",
    "        last_date = df_processed[date_col].iloc[-1]\n",
    "        next_date = last_date + pd.Timedelta(days=1)\n",
    "        axes[0, 0].plot(next_date, predictions['predicted_price'], 'ro', markersize=10, label='Prediction')\n",
    "        axes[0, 0].errorbar(next_date, predictions['predicted_price'], \n",
    "                           yerr=[[predictions['predicted_price'] - predictions['price_range_low']],\n",
    "                                 [predictions['price_range_high'] - predictions['predicted_price']]],\n",
    "                           fmt='ro', capsize=5, label='Prediction Range')\n",
    "        axes[0, 0].legend()\n",
    "    \n",
    "    # Plot 2: Price changes\n",
    "    if 'price_change_pct' in df_processed.columns:\n",
    "        axes[0, 1].plot(df_processed[date_col], df_processed['price_change_pct'], alpha=0.7)\n",
    "        axes[0, 1].axhline(y=0, color='r', linestyle='--', alpha=0.5)\n",
    "        axes[0, 1].set_title('Price Change Percentage', fontsize=14, fontweight='bold')\n",
    "        axes[0, 1].set_xlabel('Date')\n",
    "        axes[0, 1].set_ylabel('Change (%)')\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Moving averages\n",
    "    if 'ma_7' in df_processed.columns and 'ma_30' in df_processed.columns:\n",
    "        axes[1, 0].plot(df_processed[date_col], df_processed[price_col], label='Price', alpha=0.7)\n",
    "        axes[1, 0].plot(df_processed[date_col], df_processed['ma_7'], label='MA 7', linewidth=2)\n",
    "        axes[1, 0].plot(df_processed[date_col], df_processed['ma_30'], label='MA 30', linewidth=2)\n",
    "        axes[1, 0].set_title('Price with Moving Averages', fontsize=14, fontweight='bold')\n",
    "        axes[1, 0].set_xlabel('Date')\n",
    "        axes[1, 0].set_ylabel('Price (USD/oz)')\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: News sentiment and price indicators\n",
    "    if 'news_df' in locals() and not news_df.empty and 'sentiment_stats' in locals():\n",
    "        # Create combined sentiment visualization\n",
    "        rise_fall_counts = [\n",
    "            sentiment_stats.get('rise_indicator_count', 0),\n",
    "            sentiment_stats.get('fall_indicator_count', 0)\n",
    "        ]\n",
    "        labels = ['Rise Indicators', 'Fall Indicators']\n",
    "        colors = ['green', 'red']\n",
    "        axes[1, 1].bar(labels, rise_fall_counts, color=colors, alpha=0.7)\n",
    "        axes[1, 1].set_title('News Price Direction Indicators', fontsize=14, fontweight='bold')\n",
    "        axes[1, 1].set_ylabel('Number of News Items')\n",
    "        axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Add combined sentiment score as text\n",
    "        combined_sent = sentiment_stats.get('avg_combined_sentiment', 0.0)\n",
    "        if combined_sent > 0.1:\n",
    "            signal_text = 'RISE Signal'\n",
    "            signal_color = 'green'\n",
    "        elif combined_sent < -0.1:\n",
    "            signal_text = 'FALL Signal'\n",
    "            signal_color = 'red'\n",
    "        else:\n",
    "            signal_text = 'NEUTRAL'\n",
    "            signal_color = 'gray'\n",
    "        \n",
    "        max_count = max(rise_fall_counts) if rise_fall_counts and max(rise_fall_counts) > 0 else 1\n",
    "        axes[1, 1].text(0.5, max_count * 0.9, f'Signal: {signal_text}', \n",
    "                       ha='center', fontsize=12, fontweight='bold', color=signal_color,\n",
    "                       transform=axes[1, 1].transData)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Data not available for visualization\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Notes and Next Steps\n",
    "\n",
    "### API Configuration:\n",
    "- **Alpha Vantage**: Used for real-time gold price data (API key configured in Configuration section)\n",
    "- **Google RSS**: Used for news sentiment analysis with gold-specific price indicators\n",
    "\n",
    "### Model Improvements:\n",
    "- Use more sophisticated models (LSTM, XGBoost, etc.)\n",
    "- Implement prediction intervals for better uncertainty estimation\n",
    "- Add more features (economic indicators, other commodity prices)\n",
    "- Implement time-series cross-validation\n",
    "- Add ensemble methods\n",
    "- Enhance keyword detection for news analysis\n",
    "\n",
    "### Data Updates:\n",
    "- Set up scheduled runs to fetch latest news and API prices\n",
    "- Implement real-time monitoring\n",
    "- Create alerts for significant price movements\n",
    "- Expand keyword vocabulary for better price direction prediction\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
